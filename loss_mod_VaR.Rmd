---
title: "Loss Given Default/VaR"
author: "Daniel Bereket"
date: "3/15/2017"
output: html_document
---

# Loss given default

```{r}
library(tree)
library(randomForest)
library(splines)
library(dplyr)

# Set up loss training set
loss_train <- read.csv('training_set.csv')
loss_train <- loss_train[loss_train$isDefault==1,]

# Cleaning NA values for training set
loss_train <- loss_train[!is.na(loss_train$interestRate),]
loss_train <- loss_train[!is.na(loss_train$unemploymentRate),]
loss_train <- loss_train[!is.na(loss_train$hpiState),]
loss_train <- loss_train[!is.na(loss_train$tedSpread),]
loss_train <- loss_train[!is.na(loss_train$sandp500),]
loss_train <- loss_train[!is.na(loss_train$TermInMonths),]

df <- read.csv('SBA_cleaned_data.csv')
chg_vals <- select(df, GrossChargeOffAmount)
chg_vals$loanNum <- c(1:nrow(df))
loss_train <- left_join(loss_train, chg_vals, by="loanNum") # adding charge off values


# Set up loss validation set
loss_valid <- read.csv('validation_set.csv')
loss_valid <- loss_valid[loss_valid$isDefault==1,]
loss_valid <- left_join(loss_valid, chg_vals, by="loanNum") # adding charge off values

# Cleaning NA values for validation set
loss_valid <- loss_valid[!is.na(loss_valid$interestRate),]
loss_valid <- loss_valid[!is.na(loss_valid$unemploymentRate),]
loss_valid <- loss_valid[!is.na(loss_valid$hpiState),]
loss_valid <- loss_valid[!is.na(loss_valid$tedSpread),]
loss_valid <- loss_valid[!is.na(loss_valid$sandp500),]
loss_valid <- loss_valid[!is.na(loss_valid$TermInMonths),]

# Update training & validation set to have loss ratio
loss_train$LossRatio <- loss_train$GrossChargeOffAmount / loss_train$GrossApproval
loss_train$RatioLogit <- loss_train$LossRatio / (1 + loss_train$LossRatio)

loss_valid$LossRatio <- loss_valid$GrossChargeOffAmount / loss_valid$GrossApproval
loss_valid$RatioLogit <- loss_valid$LossRatio / (1 + loss_valid$LossRatio)


# Training loss model -- linear regression (threshold)
loss.lm <- lm(LossRatio~interestRate+unemploymentRate+log(hpiState)+tedSpread+sandp500+TermInMonths, data=loss_train,na.action=na.exclude)
summary(loss.lm)

lm.losspred <- predict(loss.lm, newdata=loss_valid)
lm.mse <- mean((lm.losspred-loss_valid$LossRatio)^2)
lm.mse

# Creating log hpi state column
loss_train$loghpi <- log(loss_train$hpiState)
loss_valid$loghpi <- log(loss_valid$hpiState)

# Training loss model -- bagging
bag.tree <- randomForest(LossRatio~interestRate+unemploymentRate+loghpi+tedSpread+sandp500+TermInMonths, data=loss_train, mtry=6, ntree=90)
summary(bag.tree)

bag.losspred <- predict(bag.tree, newdata=loss_valid, type="response")
bag.mse <- mean((bag.losspred-loss_valid$LossRatio)^2)
bag.mse


# Training loss model -- random forests
rf.tree <- randomForest(GrossChargeOffAmount~interestRate+unemploymentRate+loghpi+tedSpread+sandp500+TermInMonths, data=loss_train, mtry=2, ntree=90)
summary(bag.tree)

rf.losspred <- predict(bag.tree, newdata=loss_valid, type="response")
rf.mse <- mean((rf.losspred-loss_valid$LossRatio)^2)
rf.mse

# Training loss model -- regression spline
loss.spl <- lm(LossRatio~bs(interestRate,df=3)+bs(unemploymentRate,df=3)+bs(log(hpiState),df=3)+bs(tedSpread,df=3)+bs(sandp500,df=3)+bs(TermInMonths,df=3),data=loss_train)

spl.losspred <- predict(loss.spl,newdata=loss_valid)

spl.mse <- mean((spl.losspred-loss_valid$LossRatio)^2)
spl.mse


```

# VaR Calculation

```{r}
library(PerformanceAnalytics)
library(ggplot2)

## ONE YEAR LOSSES

# Reading in test set, filtering down first row
test500_set <- read.csv('test500_full.csv')
test500_set <- test500_set[test500_set$ApprovalFiscalYear==test500_set$start,]


# Reading in sample default probabilities
def.probs <- read.csv("prob.csv")
names(def.probs)[2] <- "loanNum"
def.probs <- select(def.probs, loanNum, Prob1yr, Prob5yr)


def.probs <- filter(def.probs, !is.na(test500_set$interestRate) & !is.na(test500_set$unemploymentRate) & !is.na(test500_set$hpiState) & !is.na(test500_set$tedSpread) & !is.na(test500_set$sandp500) & !is.na(test500_set$TermInMonths))


# Cleaning NA values for training set
test500_set <- test500_set[!is.na(test500_set$interestRate),]
test500_set <- test500_set[!is.na(test500_set$unemploymentRate),]
test500_set <- test500_set[!is.na(test500_set$hpiState),]
test500_set <- test500_set[!is.na(test500_set$tedSpread),]
test500_set <- test500_set[!is.na(test500_set$sandp500),]
test500_set <- test500_set[!is.na(test500_set$TermInMonths),]




# Join tables
test500_set <- left_join(test500_set, def.probs, by="loanNum")

# Creating log hpi state column for test set
test500_set$loghpi <- log(test500_set$hpiState)

# Test loss predictions -- using random forests
test.loss <- predict(rf.tree, newdata=test500_set)

firstloss.1 <- rep(0,10000)
loss.var95.1 <- rep(0,1000)
loss.avar95.1 <- rep(0,1000)
loss.var99.1 <- rep(0,1000)
loss.avar99.1 <- rep(0,1000)

set.seed(1)

# Simulate defaults
for (i in 1:10000) {
  r.prob <- runif(1,0,1)
  
  #def.events <- ifelse(def.probs$Prob1yr>r.prob,1,0)
  def.events <- rep(0, nrow(def.probs))
  for (j in 1:nrow(def.probs)) {
    if (def.probs$Prob1yr[j]>r.prob) {
      def.events[j] <- 1
    } else {
      def.events[j] <- 0
    }
  }
  
  
  def.loss <- test.loss * test500_set$GrossApproval * def.events
  
  def.total.loss <- sum(def.loss)
  firstloss.1[i] <- def.total.loss
  
}

# Create loss matrix -- CHANGE ONCE 
nvals <- firstloss.1[firstloss.1>0]
loss.matrix.1 <- matrix(nrow=10000, ncol=length(nvals))
loss.matrix.1[1,] <- nvals

# Plot losses
ls.1 <- ggplot() + geom_density(mapping=aes(x=loss.matrix.1[1,]))
ls.1

# Calculating VaR
loss.var95.1[1] <- quantile(loss.matrix.1[1,], probs=0.95,na.rm=TRUE)
loss.var99.1[1] <- quantile(loss.matrix.1[1,], probs=0.99,na.rm=TRUE)


# Bootstrapping
for (i in 2:10000) {
  boot.loss.cols <- sample(1:ncol(loss.matrix.1), ncol(loss.matrix.1), replace=TRUE)
  boot.loss <- loss.matrix.1[1,boot.loss.cols]

  
  loss.matrix.1[i,] <- boot.loss
  
  # Calculating VaR
  loss.var95.1[i] <- quantile(boot.loss, probs=seq(0.95), na.rm=TRUE)
  loss.var99.1[i] <- quantile(boot.loss, probs=seq(0.99), na.rm=TRUE)
  
}

# Plot VaR Values
pl.95.1 <- ggplot() + geom_density(mapping=aes(x=loss.var95.1))
pl.95.1
pl.99.1 <- ggplot() + geom_density(mapping=aes(x=loss.var99.1))
pl.99.1

# Tranches
lossvector.1 <- unlist(loss.matrix.1)

maxloss <- sum(test500_set$GrossApproval)
thresh5.1 <- 0.05*maxloss
thresh15.1 <- 0.15*maxloss

junior.tranche.1 <- ifelse(lossvector.1 > thresh5.1, min(c(100, (lossvector.1-thresh5.1)/thresh15.1)), 0)
senior.tranche.1 <- ifelse(lossvector.1 > thresh15.1, (lossvector.1-thresh15.1)/maxloss, 0)

junior.plot.1 <- hist(junior.tranche.1)
senior.plot.1 <- hist(senior.tranche.1)


## FIVE YEAR LOSSES

firstloss.5 <- rep(0,10000)
loss.var95.5 <- rep(0,1000)
loss.avar95.5 <- rep(0,1000)
loss.var99.5 <- rep(0,1000)
loss.avar99.5 <- rep(0,1000)


# Simulate defaults
for (i in 1:10000) {
  r.prob <- runif(1,0,1)
  
  def.events <- ifelse(def.probs$Prob5yr>r.prob,1,0)
  def.loss <- test.loss * test500_set$GrossApproval * def.events
  
  def.total.loss <- sum(def.loss)
  firstloss[i] <- def.total.loss
}

# Create loss matrix
nvals <- firstloss.5[firstloss.5>0]
loss.matrix.5 <- matrix(nrow=10000, ncol=length(nvals))
loss.matrix.5[1,] <- nvals

# Plot losses
ls.5 <- ggplot() + geom_density(mapping=aes(x=loss.matrix.5[1,]))
ls.5

# Calculate VaR 
loss.var95.5[1] <- quantile(loss.matrix.5[1,], probs=0.95,na.rm=TRUE)
loss.var99.5[1] <- quantile(loss.matrix.5[1,], probs=0.99,na.rm=TRUE)
# Do AVaR later


# Bootstrapping
for (i in 2:10000) {
  boot.loss.cols <- sample(1:ncol(loss.matrix.5), ncol(loss.matrix.5), replace=TRUE)
  boot.loss <- loss.matrix.5[1,boot.loss.cols]
  
  # Calculating VaR
  loss.var95.5[i] <- quantile(loss.matrix.5[i,], probs=0.95,na.rm=TRUE)
  loss.var99.5[i] <- quantile(loss.matrix.5[i,], probs=0.99,na.rm=TRUE)
}

# Plot VaR curve
pl.95.5 <- ggplot() + geom_density(mapping=aes(x=loss.var95.5))
pl.95.5
pl.99.5 <- ggplot() + geom_density(mapping=aes(x=loss.var99.5))
pl.99.5

# Tranches
lossvector.5 <- unlist(loss.matrix.5)

thresh5.5 <- 0.05*maxloss
thresh15.5 <- 0.15*maxloss

junior.tranche.5 <- ifelse(lossvector.5 > thresh5.5, min(c(100, (lossvector.5-thresh5.5)/thresh15.5)), 0)
senior.tranche.5 <- ifelse(lossvector.5 > thresh15.5, (lossvector.5-thresh15.5)/maxloss, 0)

junior.plot.5 <- hist(junior.tranche.5)
senior.plot.5 <- hist(senior.tranche.5)
```

