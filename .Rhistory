model <- h2o.deeplearning(x = x,  # column names for predictors
y = y,   # column name for label
training_frame = train_h2o, # train data in H2O format
validation_frame = valid_h2o, # test data in H2O format
distribution = "multinomial", # used for multi-classification
activation = "RectifierWithDropout", # activation function
hidden = c(200,200,200), # number of nodes in hidden layers (3 layers with 200 nodes each)
input_dropout_ratio = 0.2, # A fraction of the features for each training row to omit from training in order to improve generalization (dimension sampling).
l1 = 1e-5, # l1 regularization
epochs = 10) # number of iterations
model@parameters
model
h2o.performance(model, train = TRUE)
h2o.performance(model, valid = TRUE)
h2o.mse(model, valid = TRUE)
pred <- h2o.predict(model, newdata = test_h2o)
head(pred)
y_hat = as.data.frame(pred)[,1]
head(y_hat)
err = 1 - mean(y_hat == test$Resolution_Type)
err
err = 1 - mean(y_hat == df.test.ts$isDefault)
err
h2o.shutdown(prompt = FALSE)
rm(list = ls())
localH2O <- h2o.init(ip = "localhost", port = 54321, startH2O = TRUE, nthreads = -1)
df <- read.csv("SBA_cleaned_data.csv")
df <- df[,-c(1)]
df <- df[,-c("LoanStatus","ChargeOffDate","GrossChargeOffAmount")]
# Creation of Train, Validation and Test set for Time Series Sampling
df.train.ts <- filter(df,ApprovalFiscalYear <= 2002)
df.valid.ts <- filter(df,ApprovalFiscalYear > 2002 & ApprovalFiscalYear <= 2006)
df.test.ts <- filter(df,ApprovalFiscalYear>2006)
train_h2o <- as.h2o(df.train.ts)
valid_h2o <- as.h2o(df.valid.ts)
test_h2o <- as.h2o(df.test.ts)
h2o.describe(train_h2o)
h2o.describe(valid_h2o)
h2o.describe(test_h2o)
# getting the column names
y <- "isDefault"
x <- setdiff(names(train_h2o), y)
train_h2o[,y] <- as.factor(train_h2o[,y])
valid_h2o[,y] <- as.factor(valid_h2o[,y])
test_h2o[,y] <- as.factor(test_h2o[,y])
View(df)
df <- read.csv("SBA_cleaned_data.csv")
df <- df[,-c(1)]
df <- df[,-c("LoanStatus","ChargeOffDate","GrossChargeOffAmount")]
df <- subset(df, -c("LoanStatus","ChargeOffDate","GrossChargeOffAmount"))
df <- subset(df, select = -c("LoanStatus","ChargeOffDate","GrossChargeOffAmount"))
df <- subset(df, select = -c(LoanStatus,ChargeOffDate,GrossChargeOffAmount))
df <- read.csv("SBA_cleaned_data.csv")
df <- df[,-c(1)]
df <- subset(df, select = -c(LoanStatus,ChargeOffDate,GrossChargeOffAmount))
# Creation of Train, Validation and Test set for Time Series Sampling
df.train.ts <- filter(df,ApprovalFiscalYear <= 2002)
df.valid.ts <- filter(df,ApprovalFiscalYear > 2002 & ApprovalFiscalYear <= 2006)
df.test.ts <- filter(df,ApprovalFiscalYear>2006)
train_h2o <- as.h2o(df.train.ts)
valid_h2o <- as.h2o(df.valid.ts)
test_h2o <- as.h2o(df.test.ts)
h2o.describe(train_h2o)
h2o.describe(valid_h2o)
h2o.describe(test_h2o)
# getting the column names
y <- "isDefault"
x <- setdiff(names(train_h2o), y)
train_h2o[,y] <- as.factor(train_h2o[,y])
valid_h2o[,y] <- as.factor(valid_h2o[,y])
test_h2o[,y] <- as.factor(test_h2o[,y])
model <- h2o.deeplearning(x = x,  # column names for predictors
y = y,   # column name for label
training_frame = train_h2o, # train data in H2O format
validation_frame = valid_h2o, # test data in H2O format
distribution = "multinomial", # used for multi-classification
activation = "RectifierWithDropout", # activation function
hidden = c(200,200,200), # number of nodes in hidden layers (3 layers with 200 nodes each)
input_dropout_ratio = 0.2, # A fraction of the features for each training row to omit from training in order to improve generalization (dimension sampling).
l1 = 1e-5, # l1 regularization
epochs = 10) # number of iterations
model@parameters
model
# training set metrics
h2o.performance(model, train = TRUE)
# validation set metrics
# randomly sampled training points to be used for scoring (the default uses 10,000 points)
h2o.performance(model, valid = TRUE)
# Get MSE only
h2o.mse(model, valid = TRUE)
# making predictions (in terms of probability)
pred <- h2o.predict(model, newdata = test_h2o)
head(pred)
# converting the prediction object from h2o formato to a data frame
y_hat = as.data.frame(pred)[,1]
head(y_hat)
# calculating classification error
err = 1 - mean(y_hat == df.test.ts$isDefault)
err
df <- read.csv("SBA_cleaned_data.csv")
df <- df[,-c(1)]
df <- subset(df, select = -c(LoanStatus,ChargeOffDate,GrossChargeOffAmount,dayselapsed))
# Creation of Train, Validation and Test set for Time Series Sampling
df.train.ts <- filter(df,ApprovalFiscalYear <= 2002)
df.valid.ts <- filter(df,ApprovalFiscalYear > 2002 & ApprovalFiscalYear <= 2006)
df.test.ts <- filter(df,ApprovalFiscalYear>2006)
train_h2o <- as.h2o(df.train.ts)
valid_h2o <- as.h2o(df.valid.ts)
test_h2o <- as.h2o(df.test.ts)
h2o.describe(train_h2o)
h2o.describe(valid_h2o)
h2o.describe(test_h2o)
# getting the column names
y <- "isDefault"
x <- setdiff(names(train_h2o), y)
train_h2o[,y] <- as.factor(train_h2o[,y])
valid_h2o[,y] <- as.factor(valid_h2o[,y])
test_h2o[,y] <- as.factor(test_h2o[,y])
model <- h2o.deeplearning(x = x,  # column names for predictors
y = y,   # column name for label
training_frame = train_h2o, # train data in H2O format
validation_frame = valid_h2o, # test data in H2O format
distribution = "multinomial", # used for multi-classification
activation = "RectifierWithDropout", # activation function
hidden = c(200,200,200), # number of nodes in hidden layers (3 layers with 200 nodes each)
input_dropout_ratio = 0.2, # A fraction of the features for each training row to omit from training in order to improve generalization (dimension sampling).
l1 = 1e-5, # l1 regularization
epochs = 10) # number of iterations
View(df)
View(df)
df <- read.csv("SBA_cleaned_data.csv")
df <- df[,-c(1)]
df <- subset(df, select = -c(LoanStatus,ChargeOffDate,GrossChargeOffAmount,dayselapsed))
# Creation of Train, Validation and Test set for Time Series Sampling
df.train.ts <- filter(df,ApprovalFiscalYear <= 2002)
df.valid.ts <- filter(df,ApprovalFiscalYear > 2002 & ApprovalFiscalYear <= 2006)
df.test.ts <- filter(df,ApprovalFiscalYear>2006)
train_h2o <- as.h2o(df.train.ts)
valid_h2o <- as.h2o(df.valid.ts)
test_h2o <- as.h2o(df.test.ts)
h2o.describe(train_h2o)
h2o.describe(valid_h2o)
h2o.describe(test_h2o)
# getting the column names
y <- "isDefault"
x <- setdiff(names(train_h2o), y)
train_h2o[,y] <- as.factor(train_h2o[,y])
valid_h2o[,y] <- as.factor(valid_h2o[,y])
test_h2o[,y] <- as.factor(test_h2o[,y])
model <- h2o.deeplearning(x = x,  # column names for predictors
y = y,   # column name for label
training_frame = train_h2o, # train data in H2O format
validation_frame = valid_h2o, # test data in H2O format
distribution = "multinomial", # used for multi-classification
activation = "RectifierWithDropout", # activation function
hidden = c(200,200,200), # number of nodes in hidden layers (3 layers with 200 nodes each)
input_dropout_ratio = 0.2, # A fraction of the features for each training row to omit from training in order to improve generalization (dimension sampling).
l1 = 1e-5, # l1 regularization
epochs = 10) # number of iterations
model@parameters
model
# training set metrics
h2o.performance(model, train = TRUE)
# validation set metrics
# randomly sampled training points to be used for scoring (the default uses 10,000 points)
h2o.performance(model, valid = TRUE)
# Get MSE only
h2o.mse(model, valid = TRUE)
# making predictions (in terms of probability)
pred <- h2o.predict(model, newdata = test_h2o)
head(pred)
# converting the prediction object from h2o formato to a data frame
y_hat = as.data.frame(pred)[,1]
head(y_hat)
# calculating classification error
err = 1 - mean(y_hat == df.test.ts$isDefault)
err
?h2o.deeplearning
model <- h2o.deeplearning(x = x,  # column names for predictors
y = y,   # column name for label
training_frame = train_h2o, # train data in H2O format
validation_frame = valid_h2o, # test data in H2O format
distribution = "multinomial", # used for multi-classification
activation = "RectifierWithDropout", # activation function
hidden = c(50,50,50), # number of nodes in hidden layers (3 layers with 200 nodes each)
input_dropout_ratio = 0.2, # A fraction of the features for each training row to omit from training in order to improve generalization (dimension sampling).
l1 = 1e-5, # l1 regularization
epochs = 10) # number of iterations
# View the specified parameters of your deep learning model
model@parameters
model
# training set metrics
h2o.performance(model, train = TRUE)
# validation set metrics
# randomly sampled training points to be used for scoring (the default uses 10,000 points)
h2o.performance(model, valid = TRUE)
# Get MSE only
h2o.mse(model, valid = TRUE)
# making predictions (in terms of probability)
pred <- h2o.predict(model, newdata = test_h2o)
head(pred)
# converting the prediction object from h2o formato to a data frame
y_hat = as.data.frame(pred)[,1]
head(y_hat)
# calculating classification error
err = 1 - mean(y_hat == df.test.ts$isDefault)
err
model <- h2o.deeplearning(x = x,  # column names for predictors
y = y,   # column name for label
training_frame = train_h2o, # train data in H2O format
validation_frame = valid_h2o, # test data in H2O format
distribution = "multinomial", # used for multi-classification
activation = "RectifierWithDropout", # activation function
hidden = c(10,10,10), # number of nodes in hidden layers (3 layers with 200 nodes each)
input_dropout_ratio = 0.2, # A fraction of the features for each training row to omit from training in order to improve generalization (dimension sampling).
l1 = 1e-5, # l1 regularization
epochs = 10) # number of iterations
# View the specified parameters of your deep learning model
model@parameters
model
# training set metrics
h2o.performance(model, train = TRUE)
# validation set metrics
# randomly sampled training points to be used for scoring (the default uses 10,000 points)
h2o.performance(model, valid = TRUE)
# Get MSE only
h2o.mse(model, valid = TRUE)
# making predictions (in terms of probability)
pred <- h2o.predict(model, newdata = test_h2o)
head(pred)
# converting the prediction object from h2o formato to a data frame
y_hat = as.data.frame(pred)[,1]
head(y_hat)
# calculating classification error
err = 1 - mean(y_hat == df.test.ts$isDefault)
err
model <- h2o.deeplearning(x = x,  # column names for predictors
y = y,   # column name for label
training_frame = train_h2o, # train data in H2O format
validation_frame = valid_h2o, # test data in H2O format
distribution = "multinomial", # used for multi-classification
activation = "RectifierWithDropout", # activation function
hidden = c(5,5,5), # number of nodes in hidden layers (3 layers with 200 nodes each)
input_dropout_ratio = 0.2, # A fraction of the features for each training row to omit from training in order to improve generalization (dimension sampling).
l1 = 1e-5, # l1 regularization
epochs = 10) # number of iterations
# View the specified parameters of your deep learning model
model@parameters
model
# training set metrics
h2o.performance(model, train = TRUE)
# validation set metrics
# randomly sampled training points to be used for scoring (the default uses 10,000 points)
h2o.performance(model, valid = TRUE)
# Get MSE only
h2o.mse(model, valid = TRUE)
# making predictions (in terms of probability)
pred <- h2o.predict(model, newdata = test_h2o)
head(pred)
# converting the prediction object from h2o formato to a data frame
y_hat = as.data.frame(pred)[,1]
head(y_hat)
# calculating classification error
err = 1 - mean(y_hat == df.test.ts$isDefault)
err
h2o.shutdown(prompt = FALSE)
model <- h2o.deeplearning(x = x,  # column names for predictors
y = y,   # column name for label
training_frame = train_h2o, # train data in H2O format
validation_frame = valid_h2o, # test data in H2O format
distribution = "multinomial", # used for multi-classification
activation = "RectifierWithDropout", # activation function
hidden = c(5,5), # number of nodes in hidden layers (3 layers with 200 nodes each)
input_dropout_ratio = 0.2, # A fraction of the features for each training row to omit from training in order to improve generalization (dimension sampling).
l1 = 1e-5, # l1 regularization
epochs = 10) # number of iterations
# View the specified parameters of your deep learning model
model@parameters
model
# training set metrics
h2o.performance(model, train = TRUE)
# validation set metrics
# randomly sampled training points to be used for scoring (the default uses 10,000 points)
h2o.performance(model, valid = TRUE)
# Get MSE only
h2o.mse(model, valid = TRUE)
# making predictions (in terms of probability)
pred <- h2o.predict(model, newdata = test_h2o)
head(pred)
# converting the prediction object from h2o formato to a data frame
y_hat = as.data.frame(pred)[,1]
head(y_hat)
# calculating classification error
err = 1 - mean(y_hat == df.test.ts$isDefault)
err
h2o.shutdown(prompt = FALSE)
localH2O <- h2o.init(ip = "localhost", port = 54321, startH2O = TRUE, nthreads = -1)
model <- h2o.deeplearning(x = x,  # column names for predictors
y = y,   # column name for label
training_frame = train_h2o, # train data in H2O format
validation_frame = valid_h2o, # test data in H2O format
distribution = "multinomial", # used for multi-classification
activation = "RectifierWithDropout", # activation function
hidden = c(5,5), # number of nodes in hidden layers (3 layers with 200 nodes each)
input_dropout_ratio = 0.2, # A fraction of the features for each training row to omit from training in order to improve generalization (dimension sampling).
l1 = 1e-5, # l1 regularization
epochs = 10) # number of iterations
# View the specified parameters of your deep learning model
model@parameters
model
# training set metrics
h2o.performance(model, train = TRUE)
# validation set metrics
# randomly sampled training points to be used for scoring (the default uses 10,000 points)
h2o.performance(model, valid = TRUE)
# Get MSE only
h2o.mse(model, valid = TRUE)
# making predictions (in terms of probability)
pred <- h2o.predict(model, newdata = test_h2o)
head(pred)
# converting the prediction object from h2o formato to a data frame
y_hat = as.data.frame(pred)[,1]
head(y_hat)
# calculating classification error
err = 1 - mean(y_hat == df.test.ts$isDefault)
err
model <- h2o.deeplearning(x = x,  # column names for predictors
y = y,   # column name for label
training_frame = train_h2o, # train data in H2O format
validation_frame = valid_h2o, # test data in H2O format
distribution = "multinomial", # used for multi-classification
activation = "RectifierWithDropout", # activation function
hidden = c(5,5), # number of nodes in hidden layers (3 layers with 200 nodes each)
input_dropout_ratio = 0.2, # A fraction of the features for each training row to omit from training in order to improve generalization (dimension sampling).
l1 = 1e-5, # l1 regularization
epochs = 10) # number of iterations
df <- read.csv("SBA_cleaned_data.csv")
df <- df[,-c(1)]
df <- subset(df, select = -c(LoanStatus,ChargeOffDate,GrossChargeOffAmount,dayselapsed))
# Creation of Train, Validation and Test set for Time Series Sampling
df.train.ts <- filter(df,ApprovalFiscalYear <= 2002)
df.valid.ts <- filter(df,ApprovalFiscalYear > 2002 & ApprovalFiscalYear <= 2006)
df.test.ts <- filter(df,ApprovalFiscalYear>2006)
train_h2o <- as.h2o(df.train.ts)
valid_h2o <- as.h2o(df.valid.ts)
test_h2o <- as.h2o(df.test.ts)
h2o.describe(train_h2o)
h2o.describe(valid_h2o)
h2o.describe(test_h2o)
# getting the column names
y <- "isDefault"
x <- setdiff(names(train_h2o), y)
train_h2o[,y] <- as.factor(train_h2o[,y])
valid_h2o[,y] <- as.factor(valid_h2o[,y])
test_h2o[,y] <- as.factor(test_h2o[,y])
model <- h2o.deeplearning(x = x,  # column names for predictors
y = y,   # column name for label
training_frame = train_h2o, # train data in H2O format
validation_frame = valid_h2o, # test data in H2O format
distribution = "multinomial", # used for multi-classification
activation = "RectifierWithDropout", # activation function
hidden = c(5,5), # number of nodes in hidden layers (3 layers with 200 nodes each)
input_dropout_ratio = 0.2, # A fraction of the features for each training row to omit from training in order to improve generalization (dimension sampling).
l1 = 1e-5, # l1 regularization
epochs = 10) # number of iterations
df <- read.csv("SBA_cleaned_data.csv")
df <- df[,-c(1)]
df <- subset(df, select = -c(LoanStatus,ChargeOffDate,GrossChargeOffAmount,dayselapsed))
# Creation of Train, Validation and Test set for Time Series Sampling
df.train.ts <- filter(df,ApprovalFiscalYear <= 2002)
df.valid.ts <- filter(df,ApprovalFiscalYear > 2002 & ApprovalFiscalYear <= 2006)
df.test.ts <- filter(df,ApprovalFiscalYear>2006)
train_h2o <- as.h2o(df.train.ts)
valid_h2o <- as.h2o(df.valid.ts)
test_h2o <- as.h2o(df.test.ts)
h2o.describe(train_h2o)
h2o.describe(valid_h2o)
h2o.describe(test_h2o)
# getting the column names
y <- "isDefault"
x <- setdiff(names(train_h2o), y)
train_h2o[,y] <- as.factor(train_h2o[,y])
valid_h2o[,y] <- as.factor(valid_h2o[,y])
test_h2o[,y] <- as.factor(test_h2o[,y])
model <- h2o.deeplearning(x = x,  # column names for predictors
y = y,   # column name for label
training_frame = train_h2o, # train data in H2O format
validation_frame = valid_h2o, # test data in H2O format
distribution = "multinomial", # used for multi-classification
activation = "RectifierWithDropout", # activation function
hidden = c(5,5), # number of nodes in hidden layers (3 layers with 200 nodes each)
input_dropout_ratio = 0.2, # A fraction of the features for each training row to omit from training in order to improve generalization (dimension sampling).
l1 = 1e-5, # l1 regularization
epochs = 10) # number of iterations
model@parameters
model
# training set metrics
h2o.performance(model, train = TRUE)
# validation set metrics
# randomly sampled training points to be used for scoring (the default uses 10,000 points)
h2o.performance(model, valid = TRUE)
# Get MSE only
h2o.mse(model, valid = TRUE)
# making predictions (in terms of probability)
pred <- h2o.predict(model, newdata = test_h2o)
head(pred)
# converting the prediction object from h2o formato to a data frame
y_hat = as.data.frame(pred)[,1]
head(y_hat)
# calculating classification error
err = 1 - mean(y_hat == df.test.ts$isDefault)
err
model <- h2o.deeplearning(x = x,  # column names for predictors
y = y,   # column name for label
training_frame = train_h2o, # train data in H2O format
validation_frame = valid_h2o, # test data in H2O format
distribution = "multinomial", # used for multi-classification
activation = "RectifierWithDropout", # activation function
hidden = c(10), # number of nodes in hidden layers (3 layers with 200 nodes each)
input_dropout_ratio = 0.2, # A fraction of the features for each training row to omit from training in order to improve generalization (dimension sampling).
l1 = 1e-5, # l1 regularization
epochs = 10) # number of iterations
# View the specified parameters of your deep learning model
model@parameters
model
# training set metrics
h2o.performance(model, train = TRUE)
# validation set metrics
# randomly sampled training points to be used for scoring (the default uses 10,000 points)
h2o.performance(model, valid = TRUE)
# Get MSE only
h2o.mse(model, valid = TRUE)
# making predictions (in terms of probability)
pred <- h2o.predict(model, newdata = test_h2o)
head(pred)
# converting the prediction object from h2o formato to a data frame
y_hat = as.data.frame(pred)[,1]
head(y_hat)
# calculating classification error
err = 1 - mean(y_hat == df.test.ts$isDefault)
err
model <- h2o.deeplearning(x = x,  # column names for predictors
y = y,   # column name for label
training_frame = train_h2o, # train data in H2O format
validation_frame = valid_h2o, # test data in H2O format
distribution = "multinomial", # used for multi-classification
activation = "RectifierWithDropout", # activation function
hidden = c(200), # number of nodes in hidden layers (3 layers with 200 nodes each)
input_dropout_ratio = 0.2, # A fraction of the features for each training row to omit from training in order to improve generalization (dimension sampling).
l1 = 1e-5, # l1 regularization
epochs = 10) # number of iterations
# View the specified parameters of your deep learning model
model@parameters
model
# training set metrics
h2o.performance(model, train = TRUE)
# validation set metrics
# randomly sampled training points to be used for scoring (the default uses 10,000 points)
h2o.performance(model, valid = TRUE)
# Get MSE only
h2o.mse(model, valid = TRUE)
# making predictions (in terms of probability)
pred <- h2o.predict(model, newdata = test_h2o)
head(pred)
# converting the prediction object from h2o formato to a data frame
y_hat = as.data.frame(pred)[,1]
head(y_hat)
# calculating classification error
err = 1 - mean(y_hat == df.test.ts$isDefault)
err
model <- h2o.deeplearning(x = x,  # column names for predictors
y = y,   # column name for label
training_frame = train_h2o, # train data in H2O format
validation_frame = valid_h2o, # test data in H2O format
distribution = "multinomial", # used for multi-classification
activation = "RectifierWithDropout", # activation function
hidden = c(0), # number of nodes in hidden layers (3 layers with 200 nodes each)
input_dropout_ratio = 0.2, # A fraction of the features for each training row to omit from training in order to improve generalization (dimension sampling).
l1 = 1e-5, # l1 regularization
epochs = 10) # number of iterations
model <- h2o.deeplearning(x = x,  # column names for predictors
y = y,   # column name for label
training_frame = train_h2o, # train data in H2O format
validation_frame = valid_h2o, # test data in H2O format
distribution = "multinomial", # used for multi-classification
activation = "RectifierWithDropout", # activation function
hidden = c(1), # number of nodes in hidden layers (3 layers with 200 nodes each)
input_dropout_ratio = 0.2, # A fraction of the features for each training row to omit from training in order to improve generalization (dimension sampling).
l1 = 1e-5, # l1 regularization
epochs = 10) # number of iterations
# View the specified parameters of your deep learning model
model@parameters
model
# training set metrics
h2o.performance(model, train = TRUE)
# validation set metrics
# randomly sampled training points to be used for scoring (the default uses 10,000 points)
h2o.performance(model, valid = TRUE)
# Get MSE only
h2o.mse(model, valid = TRUE)
# making predictions (in terms of probability)
pred <- h2o.predict(model, newdata = test_h2o)
head(pred)
# converting the prediction object from h2o formato to a data frame
y_hat = as.data.frame(pred)[,1]
head(y_hat)
# calculating classification error
err = 1 - mean(y_hat == df.test.ts$isDefault)
err
View(df)
?interaction
interaction("AK",1990)
