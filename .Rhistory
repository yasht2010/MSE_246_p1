# Fourth set of correlations
comatrix[4,1] <- comatrix[1,4]
comatrix[4,2] <- comatrix[2,4]
comatrix[4,3] <- comatrix[3,4]
comatrix[4,4] <- cov(d,d)
return(comatrix)
}
## PART 1: DOWNLOADING AND EXPORTING DATA
# Downloading data
xcid <- getSymbols(Symbols='^XCI',auto.assign=FALSE,from='1995-01-03',to='2016-10-28')
xoid <- getSymbols(Symbols="^XOI", auto.assign=FALSE,from='1995-01-03',to='2016-10-28')
xbdd <- getSymbols(Symbols='^XBD',auto.assign=FALSE,from='1995-01-03',to='2016-10-28')
btkd <- getSymbols(Symbols='^BTK',auto.assign=FALSE,from='1995-01-03',to='2016-10-28')
gspcd <- getSymbols(Symbols='^GSPC',auto.assign=FALSE,from='1995-01-03',to='2016-10-28')
# Exporting original data
write.csv(xcid,file='xci_data.csv')
write.csv(xoid,file='xoi_data.csv')
write.csv(xbdd,file='xbd_data.csv')
write.csv(btkd,file='btk_data.csv')
write.csv(gspcd,file='gspc_data.csv')
# Calculating weekly returns, removing superfluous row in objects (for weekend return in 2001)
xciweek <- weeklyReturn(xcid,subset='1995-01-02::2016-10-28')
xciweek <- xciweek[time(xciweek) != '2001-09-10']
xoiweek <- weeklyReturn(xoid,subset='1995-01-02::2016-10-28')
xoiweek <- xoiweek[time(xoiweek) != '2001-09-10']
xbdweek <- weeklyReturn(xbdd,subset='1995-01-02::2016-10-28')
xbdweek <- xbdweek[time(xbdweek) != '2001-09-10']
btkweek <- weeklyReturn(btkd,subset='1995-01-02::2016-10-28')
btkweek <- btkweek[time(btkweek) != '2001-09-10']
gspcweek <- weeklyReturn(gspcd,subset='1995-01-02::2016-10-28')
gspcweek <- gspcweek[time(gspcweek) != '2001-09-10']
# Exporting weekly data
write.csv(xciweek,file='xci_weekly_returns.csv')
write.csv(xoiweek,file='xoi_weekly_returns.csv')
write.csv(xbdweek,file='xbd_weekly_returns.csv')
write.csv(btkweek,file='btk_weekly_returns.csv')
write.csv(gspcweek,file='gspc_weekly_returns.csv')
## PART 2: CALCULATING PARAMETERS
# Weekly expected return
xci_avg_week <- mean(xciweek$weekly.returns)
xoi_avg_week <- mean(xoiweek$weekly.returns)
xbd_avg_week <- mean(xbdweek$weekly.returns)
btk_avg_week <- mean(btkweek$weekly.returns)
gspc_avg_week <- mean(gspcweek$weekly.returns)
# Estimated yearly expected return
xci_est_yearly <- xci_avg_week*52
xoi_est_yearly <- xoi_avg_week*52
xbd_est_yearly <- xbd_avg_week*52
btk_est_yearly <- btk_avg_week*52
gspc_est_yearly <- gspc_avg_week*52
# Weekly variance
xci_var_week <- var(xciweek$weekly.returns)
xoi_var_week <- var(xoiweek$weekly.returns)
xbd_var_week <- var(xbdweek$weekly.returns)
btk_var_week <- var(btkweek$weekly.returns)
gspc_var_week <- var(gspcweek$weekly.returns)
# Estimated yearly variance
xci_var_yearly <- xci_var_week*52
xoi_var_yearly <- xoi_var_week*52
xbd_var_yearly <- xbd_var_week*52
btk_var_yearly <- btk_var_week*52
gspc_var_yearly <- gspc_var_week*52
# Estimated standard deviation
xci_sd_yearly <- sqrt(xci_var_yearly)
xoi_sd_yearly <- sqrt(xoi_var_yearly)
xbd_sd_yearly <- sqrt(xbd_var_yearly)
btk_sd_yearly <- sqrt(btk_var_yearly)
gspc_sd_yearly <- sqrt(gspc_var_yearly)
# Standard error of yearly expected return
xci_se_mean <- xci_sd_yearly / sqrt(nrow(xciweek))
xoi_se_mean <- xoi_sd_yearly / sqrt(nrow(xoiweek))
xbd_se_mean <- xbd_sd_yearly / sqrt(nrow(xbdweek))
btk_se_mean <- btk_sd_yearly / sqrt(nrow(btkweek))
gspc_se_mean <- gspc_sd_yearly / sqrt(nrow(gspcweek))
# Standard error of the variance
xci_se_var <- xci_var_yearly*sqrt(2/(nrow(xciweek)-1))
xoi_se_var <- xoi_var_yearly*sqrt(2/(nrow(xoiweek)-1))
xbd_se_var <- xbd_var_yearly*sqrt(2/(nrow(xbdweek)-1))
btk_se_var <- btk_var_yearly*sqrt(2/(nrow(btkweek)-1))
gspc_se_var <- gspc_var_yearly*sqrt(2/(nrow(gspcweek)-1))
# Covariance of each index (first 4) with market (gspc)
xci_mk_cov <- cov((52*xciweek$weekly.returns),(52*gspcweek$weekly.returns))
xoi_mk_cov <- cov((52*xoiweek$weekly.returns),(52*gspcweek$weekly.returns))
xbd_mk_cov <- cov((52*xbdweek$weekly.returns),(52*gspcweek$weekly.returns))
btk_mk_cov <- cov((52*btkweek$weekly.returns),(52*gspcweek$weekly.returns))
# Calculating covariance matrix for different indices
cov_matrix_f <- cov_matrix_indices((52*xoiweek$weekly.returns),(52*xciweek$weekly.returns),(52*xbdweek$weekly.returns),(52*btkweek$weekly.returns))
# Calculating beta for each index
beta_xci <- xci_mk_cov / xci_var_yearly
beta_xoi <- xoi_mk_cov / xoi_var_yearly
beta_xbd <- xbd_mk_cov / xbd_var_yearly
beta_btk <- btk_mk_cov / btk_var_yearly
## PART 3: CAPM ESTIMATES
risk_f <- 0.02
xci_ret_capm <- risk_f + beta_xci*(gspc_est_yearly - risk_f)
xoi_ret_capm <- risk_f + beta_xoi*(gspc_est_yearly - risk_f)
xbd_ret_capm <- risk_f + beta_xbd*(gspc_est_yearly - risk_f)
btk_ret_capm <- risk_f + beta_btk*(gspc_est_yearly - risk_f)
View(cov_matrix_f)
cov_matrix_indices <- function(a, b, c, d) {
# a, b, c, d refer to vectors, not objects
comatrix <- matrix(nrow=4, ncol=4)
# First set of correlations
comatrix[1,1] <- 52*cov(a,a)
comatrix[1,2] <- 52*cov(a,b)
comatrix[1,3] <- 52*cov(a,c)
comatrix[1,4] <- 52*cov(a,d)
# Second set of correlations
comatrix[2,1] <- comatrix[1,2]
comatrix[2,2] <- 52*cov(b,b)
comatrix[2,3] <- 52*cov(b,c)
comatrix[2,4] <- 52*cov(b,d)
# Third set of correlations
comatrix[3,1] <- comatrix[1,3]
comatrix[3,2] <- comatrix[2,3]
comatrix[3,3] <- 52*cov(c,c)
comatrix[3,4] <- 52*cov(c,d)
# Fourth set of correlations
comatrix[4,1] <- comatrix[1,4]
comatrix[4,2] <- comatrix[2,4]
comatrix[4,3] <- comatrix[3,4]
comatrix[4,4] <- 52*cov(d,d)
return(comatrix)
}
cov_matrix_f <- cov_matrix_indices(xoiweek$weekly.returns,xciweek$weekly.returns,xbdweek$weekly.returns,btkweek$weekly.returns)
View(cov_matrix_f)
xoi_var_yearly
xci_var_yearly
xci_var_week
gspc_var_week
gspc_var_yearly
xoi_var_yearly
xci_var_yearly
xbd_var_yearly
btk_var_yearly
xci_mk_cov <- 52*cov(xciweek$weekly.returns,gspcweek$weekly.returns)
xoi_mk_cov <- 52*cov(xoiweek$weekly.returns,gspcweek$weekly.returns)
xbd_mk_cov <- 52*cov(xbdweek$weekly.returns,gspcweek$weekly.returns)
btk_mk_cov <- 52*cov(btkweek$weekly.returns,gspcweek$weekly.returns)
xoi_mk_cov
xoi_mk_cov
xci_mk_cov
xbd_mk_cov
btk_mk_cov
library('quantmod')
?return
?return
?periodReturn
?getSymbols
test <- getSymbols('^XCI',auto.assign=FALSE)
View(test)
test[1,1]
view_t <- test[1,1]
view_t
symbols <- c('^XCI', '^XOI', '^XBD', '^BTK', '^XAU', '^XAL', '^XTC', '^XNG', 'FSRX', 'XLU')
ret_data <- c(rep(1,10))
for (i in 1:10) {
curr_data <- getSymbols(Symbols=symbols[i],auto.assign=FALSE,from='2016-07-27')
ret_val <- (curr_data[nrow(curr_data),4] - curr_data[1,1]) / curr_data[1,1]
ret_val <- ret_val - 1
ret_data[i] <- ret_val
}
symbols <- c('^XCI', '^XOI', '^XBD', '^BTK', '^XAU', '^XAL', '^XTC', '^XNG', 'FSRX', 'XLU')
ret_data <- c(rep(1,10))
for (i in 1:1) {
curr_data <- getSymbols(Symbols=symbols[i],auto.assign=FALSE,from='2016-07-27')
ret_val <- (curr_data[nrow(curr_data),4] - curr_data[1,1]) / curr_data[1,1]
print(ret_val)
ret_val <- ret_val - 1
ret_data[i] <- ret_val
}
symbols <- c('^XCI', '^XOI', '^XBD', '^BTK', '^XAU', '^XAL', '^XTC', '^XNG', 'FSRX', 'XLU')
ret_data <- c(rep(1,10))
for (i in 1:1) {
curr_data <- as.data.frame(getSymbols(Symbols=symbols[i],auto.assign=FALSE,from='2016-07-27'))
ret_val <- (curr_data[nrow(curr_data),4] - curr_data[1,1]) / curr_data[1,1]
print(ret_val)
ret_val <- ret_val - 1
ret_data[i] <- ret_val
}
symbols <- c('^XCI', '^XOI', '^XBD', '^BTK', '^XAU', '^XAL', '^XTC', '^XNG', 'FSRX', 'XLU')
ret_data <- c(rep(1,10))
for (i in 1:10) {
curr_data <- as.data.frame(getSymbols(Symbols=symbols[i],auto.assign=FALSE,from='2016-07-27'))
ret_val <- (curr_data[nrow(curr_data),4] - curr_data[1,1]) / curr_data[1,1]
ret_val <- ret_val - 1
ret_data[i] <- ret_val
}
traceback()
symbols <- c('^XCI', '^XOI', '^XBD', '^BTK', '^XAU', '^XAL', '^XTC', '^XNG', 'FSRFX', 'XLU')
ret_data <- c(rep(1,10))
for (i in 1:10) {
curr_data <- as.data.frame(getSymbols(Symbols=symbols[i],auto.assign=FALSE,from='2016-07-27'))
ret_val <- (curr_data[nrow(curr_data),4] - curr_data[1,1]) / curr_data[1,1]
ret_val <- ret_val - 1
ret_data[i] <- ret_val
}
ret_data
symbols <- c('FCX', 'ABX', 'HL', 'AUY', 'KGC', 'MS', 'SCHW', 'AMTD', 'GS', 'ETFC')
ret_data <- c(rep(1,10))
for (i in 1:10) {
curr_data <- as.data.frame(getSymbols(Symbols=symbols[i],auto.assign=FALSE,from='2016-07-27'))
ret_val <- (curr_data[nrow(curr_data),4] - curr_data[1,1]) / curr_data[1,1]
ret_val <- ret_val - 1
ret_data[i] <- ret_val
}
remove(view_t)
remove(test)
symbols <- c('FCX', 'ABX', 'HL', 'AUY', 'KGC', 'MS', 'SCHW', 'AMTD', 'GS', 'ETFC')
ret_data <- c(rep(1,10))
for (i in 1:10) {
curr_data <- as.data.frame(getSymbols(Symbols=symbols[i],auto.assign=FALSE,from='2016-07-27'))
ret_val <- (curr_data[nrow(curr_data),4] - curr_data[1,1]) / curr_data[1,1]
ret_val <- ret_val - 1
ret_data[i] <- ret_val
}
ret_data
min(ret_data)
max(ret_data
)
max(ret_data)
min(ret_data)
ret_data
symbols <- c('GOLD', 'RGLD', 'AEM', 'NEM', 'SLW', 'GS', 'MKTX', 'AMP', 'PJC', 'SF')
ret_data <- c(rep(1,10))
for (i in 1:10) {
curr_data <- as.data.frame(getSymbols(Symbols=symbols[i],auto.assign=FALSE,from='2016-07-27'))
ret_val <- (curr_data[nrow(curr_data),4] - curr_data[1,1]) / curr_data[1,1]
ret_val <- ret_val - 1
ret_data[i] <- ret_val
}
ret_data
max(ret_data)
min(ret_data)
install.packages('kernlab')
library('kernlab')
install.packages('~/Downloads/stringkernels_0.8.9.tar.gz', repos=NULL,type='source')
remove.packages('~/Downloads/stringkernels_0.8.9.tar.gz', repos=NULL,type='source')
remove.packages('~/Downloads/stringkernels_0.8.9.tar.gz')
remove.packages('stringkernels')
install.packages('stringkernels')
library('stringkernels')
?ksvm
?sk
?stringdot
?gapweightkernel
?stringdot
?data
data('reuters')
x<-reuters
View(x)
?kvsm
library('kernlab')
?kvsm
?ksvm
?cross
?`cross,ksvm-method`
View(y)
data('reuters')
y<-rlabels
View(y)
?plot
library('randomForest')
library('ISLR')
ncols(Carseats)
ncol(Carseats)
library('png')
install.packages('png')
library('png')
?readPNG
?rnorm
?pnorm
?hist
?rnorm
pnorm(0.95,0,1)
qnorm(0.95,0,1)
qnorm(0.975,0,1)
?xlim
?hist
?sample
?quantile
?set.seed
?.Random.seed
?which
as.POSIXct()
?as.POSIXct()
setwd('~/Desktop/Stanford Undergrad/MS&E 246/Project/Github Code/MSE_246_p1')
knitr::opts_chunk$set(echo = TRUE)
# Starting the libraries
library(dplyr)
library(ROCR)
library(data.table)
set.seed(1)
df <- read.csv("SBA_loan_data_new.csv")
# Macroeconomic data sets
unemployment_data <- read.csv("emp-unemployment.csv")
interest_rates_data <- read.csv("FED_IR.csv")
Tornado_damage_economic <- read.csv("Tornado FL.csv")
Small_business_lending_data <- read.csv("Small_Business_lending_stats.csv")
GDPSectorData <- read.csv("GDP_Industry.csv")
TED <- read.csv("TEDRATE.csv")
SNP500 <- read.csv("SNP500.csv")
set.seed(1)
SBLR <- c(rep(0,length(df$BorrState)))
for (i in 1:length(df$BorrState)) {
SBLR[i]=Small_business_lending_data[match(df$BorrState[i],Small_business_lending_data$State),5]
}
GDP <- c(rep(0,length(df$ApprovalFiscalYear)))
set.seed(1)
#Add small business loan ratio (total small business loans issued/total small businesses per state)
df=cbind(df,SBLR)
# Average HPI Index by State for 1990-2016
hpi_state <- read.csv("hpi_state.csv", header=TRUE, stringsAsFactors=F)
hpi_state$ProjectState = as.factor(hpi_state$ProjectState)
df <- left_join(df, hpi_state, by=c("ProjectState", "ApprovalFiscalYear"))
df$mn_hpi = as.numeric(df$mn_hpi)
# Filtering out Loans which are canceled or exempt
df <- filter(df, LoanStatus != "CANCLD")
df <- filter(df, LoanStatus != "EXEMPT")
df <- filter(df, DeliveryMethod != "504REFI")
set.seed(1)
df <- subset(df,select = -c(Program,BorrName,BorrStreet,
BorrZip,CDC_Street,CDC_City,CDC_Zip))
# adding isDefault
df$isDefault <- ifelse(df$LoanStatus=="CHGOFF",1,0)
for (i in 1:nrow(df)) {
if(df$LoanStatus[i]=="PIF"){df$isDefault[i]= 2}}
df$isDefault <- factor(df$isDefault)
df$isDefault <- as.numeric(df$isDefault)
# factor conversion
df$NotSameState <- factor(df$NotSameState)
df$ThirdPartyApproved <- factor(df$ThirdPartyApproved)
# adding dayselaped
df <- mutate(df,dayselapsed = as.numeric(difftime(strptime(ChargeOffDate, format = "%m/%d/%Y"),
strptime(ApprovalDate, format = "%m/%d/%Y"))))
df$dayselapsed[is.na(df$dayselapsed)]=round(df$TermInMonths*30.4)
df$dayselapsed[is.na(df$dayselapsed)] <- 7300
# adding FinalYear
df$FinalYear=df$ApprovalFiscalYear+round((df$dayselapsed)/365)
# Removing extra columns
df <- subset(df,select = -c(ThirdPartyLender_Name,ThirdPartyLender_City,ThirdPartyLender_State,
subpgmdesc,NaicsDescription,ProjectCounty,ProjectState))
# adding Naics2digits
df <- mutate(df,Naics2digits = substr(NaicsCode,1,2))
# Getting Interest Rates
set.seed(1)
interest_rates=matrix(0,nrow=length(df$ApprovalFiscalYear),ncol=length(1990:2014))
for (i in 1:length(1990:2014)) {
interest_rates[,i]=interest_rates_data[match(1989+i,interest_rates_data$Year),2]
}
interest_rates = interest_rates[1,]
# Initializing Matrix for Adding columns
set.seed(1)
matrix_test=matrix(0,nrow=0,ncol=23)
finalMatrix=matrix(0,nrow=0,ncol=23)
tempRow = matrix(0,nrow=1,ncol=23)
end_index=0
x=c("loanNum","start","stop","interestRate","gdpIndustry","unemploymentRate","hpiState","tedSpread","sandp500",
"BorrState","CDC_State","ThirdPartyDollars","GrossApproval","ApprovalDate","ApprovalFiscalYear","DeliveryMethod",
"TermInMonths","BusinessType","NotSameState","SBLR","Naics2digits","isDefault","endIndicator")
colnames(matrix_test)=x
df_const <- as.matrix(subset(df,select = c(BorrState,CDC_State,ThirdPartyDollars,GrossApproval,
ApprovalDate,ApprovalFiscalYear,DeliveryMethod,
TermInMonths,BusinessType,NotSameState,SBLR,Naics2digits)))
for (i in 1:nrow(df)) {
start=df$ApprovalFiscalYear[i]
stop=df$ApprovalFiscalYear[i]+round(df$dayselapsed[i]/365)
periods=length(start:stop)
n=0
unemployment_start_index=match(start,unemployment_data[1,])
unemployment_state_index=match(df$BorrState[i],unemployment_data[,3])
GDP_NAICS_index=match(df$Naics2digits[i],GDPSectorData[,2])
GDP_start_index=match(start,GDPSectorData[1,])
HPI_start_index=match(interaction(df$BorrState[i],start),
interaction(hpi_state$ProjectState, hpi_state$ApprovalFiscalYear))
if(stop<=2014){
for (j in 1:periods) {
tempRow = matrix(0,nrow=1,ncol=23)
tempRow[1,1]=i
tempRow[1,2]=start+n
tempRow[1,3]=start+n+1
tempRow[1,4] = interest_rates[start-1990+j]
tempRow[1,5]=GDPSectorData[GDP_NAICS_index,GDP_start_index+n]
tempRow[1,6]=unemployment_data[unemployment_state_index,unemployment_start_index+n]
tempRow[1,7]=hpi_state[HPI_start_index+n,3]
tempRow[1,8]=TED[start-1990+j,2]
tempRow[1,9]=SNP500[start-1990+j,1]
tempRow[1,as.numeric(10:21)] = df_const[i,]
if(df$isDefault[i]==2){
if((start+n)==stop){tempRow[1,22]=1
tempRow[1,23]=1}
}
if(start+n==stop) {tempRow[1,23]=1}
n=n+1
matrix_test <- rbind(matrix_test,tempRow)
}
}
else{
for (j in 1:(2014-start)) {
tempRow = matrix(0,nrow=1,ncol=23)
tempRow[1,1]=i
tempRow[1,2]=start+n
tempRow[1,3]=start+n+1
tempRow[1,4]=interest_rates[start-1990+j]
tempRow[1,5]=GDPSectorData[GDP_NAICS_index,GDP_start_index+n]
tempRow[1,6]=unemployment_data[unemployment_state_index,unemployment_start_index+n]
tempRow[1,7]=hpi_state[HPI_start_index+n,3]
tempRow[1,8]=TED[start-1990+j,2]
tempRow[1,9]=SNP500[start-1990+j,1]
tempRow[1,10:21] = df_const[i,]
if(df$isDefault[i]==2){
if((start+n)==stop){tempRow[1,22]=1
tempRow[1,23]=1}
}
if(unemployment_start_index+n==stop) {tempRow[1,23]=1}
if(j==2014-start){tempRow[1,23]=1}
n=n+1
matrix_test <- rbind(matrix_test,tempRow)
}
}
if(nrow(matrix_test)>=1000){
finalMatrix <- rbind(finalMatrix,matrix_test)
matrix_test=matrix(0,nrow=0,ncol=23)
}
}
finalMatrix <- rbind(finalMatrix,matrix_test)
finalMatrix=as.data.frame(finalMatrix)
# Convert ApprovalDate
finalMatrix <- mutate(finalMatrix, ApprovalDate = as.numeric(difftime(strptime(ApprovalDate, format ="%m/%d/%Y"),strptime("1/1/1990", format = "%m/%d/%Y"))))
finalMatrix$start <- as.numeric(as.character(finalMatrix$start))
finalMatrix$stop <- as.numeric(as.character(finalMatrix$stop))
finalMatrix$isDefault <- as.numeric(as.character(finalMatrix$isDefault))
finalMatrix$GrossApproval <- as.numeric(as.character(finalMatrix$GrossApproval))
finalMatrix$unemploymentRate <- as.numeric(as.character(finalMatrix$unemploymentRate))
finalMatrix$interestRate <- as.numeric(as.character(finalMatrix$interestRate))
finalMatrix$hpiState <- as.numeric(as.character(finalMatrix$hpiState))
finalMatrix$TermInMonths <- as.numeric(as.character(finalMatrix$TermInMonths))
finalMatrix$SBLR <- as.numeric(as.character(finalMatrix$SBLR))
finalMatrix$tedSpread <-as.numeric(as.character(finalMatrix$tedSpread))
finalMatrix$sandp500 <- as.numeric(as.character(finalMatrix$sandp500))
finalMatrix$loanNum <- as.numeric(as.character(finalMatrix$loanNum))
# Export file
#write.csv(finalMatrix, file="big_data_Matrix.csv", col.names=FALSE)
set.seed(1)
training_set=finalMatrix[1:520847,]
test_set=finalMatrix[520848+1:nrow(finalMatrix),]
filtered_set=filter(test_set,ApprovalFiscalYear==2008,TermInMonths>=60)
filtered_set=filter(filtered_set,start==2008)
loans_sampled_test=sample(filtered_set$loanNum[1]:filtered_set$loanNum[nrow(filtered_set)],500,replace=FALSE)
loans_sampled_test=as.numeric(loans_sampled_test)
validation_set <- test_set[!(test_set$loanNum %in% loans_sampled_test),]
test500_set <- test_set[(test_set$loanNum %in% loans_sampled_test),]
loss_train <- filter(training_set, isDefault == 1)
chg_vals <- select(df, GrossChargeOffAmount)
chg_vals$loanNum <- c(1:nrow(df))
loss_train <- left_join(loss_train, chg_vals, by="loanNum") # adding charge off values
loss.mod <- lm(GrossChargeOffAmount~interestRate+unemploymentRate+hpiState+tedSpread+sandp500+BusinessType, data=loss_train)
summary(loss.mod)
?predict.lm
View(training_set)
loss.mod <- lm(GrossChargeOffAmount~interestRate+unemploymentRate+hpiState+tedSpread+sandp500+BusinessType+GrossApproval+TermInMonths, data=loss_train)
summary(loss.mod)
loss.mod <- lm(GrossChargeOffAmount~interestRate+unemploymentRate+hpiState+tedSpread+GrossApproval+TermInMonths, data=loss_train)
summary(loss.mod)
loss.mod <- lm(GrossChargeOffAmount~interestRate+unemploymentRate+hpiState+tedSpread+GrossApproval+TermInMonths+NotSameState, data=loss_train)
summary(loss.mod)
loss.mod <- lm(GrossChargeOffAmount~interestRate+unemploymentRate+hpiState+tedSpread+GrossApproval+TermInMonths+SBLR, data=loss_train)
summary(loss.mod)
# Set up loss training set
loss_train <- filter(training_set, isDefault == 1)
chg_vals <- select(df, GrossChargeOffAmount)
chg_vals$loanNum <- c(1:nrow(df))
loss_train <- left_join(loss_train, chg_vals, by="loanNum") # adding charge off values
# Set up loss validation set
loss_valid <- filter(test_set, isDefault == 1)
loss_valid <- left_join(loss_valid, chg_vals, by="loanNum") # adding charge off values
# Training loss model
loss.mod <- lm(GrossChargeOffAmount~interestRate+unemploymentRate+hpiState+tedSpread+GrossApproval+TermInMonths+SBLR, data=loss_train)
summary(loss.mod)
# Testing loss model, computing MSE
loss.pred <- predict(loss.mod, newdata=loss_valid)
loss.mse <- mean((loss_valid$GrossChargeOffAmount-loss.pred)^2)
loss.mse
View(loss_valid)
sum(is.na(loss_valid$GrossChargeOffAmount))
sum(is.na(loss.pred))
loss.pred <- loss.pred[!is.na(loss.pred),]
loss.pred <- loss.pred[!is.na(loss.pred)]
View(loss.pred)
# Set up loss training set
loss_train <- filter(training_set, isDefault == 1)
chg_vals <- select(df, GrossChargeOffAmount)
chg_vals$loanNum <- c(1:nrow(df))
loss_train <- left_join(loss_train, chg_vals, by="loanNum") # adding charge off values
loss_train <- loss_train[!is.na(loss_train$GrossChargeOffAmount),]
# Set up loss validation set
loss_valid <- filter(test_set, isDefault == 1)
loss_valid <- left_join(loss_valid, chg_vals, by="loanNum") # adding charge off values
loss_valid <- loss_valid[!is.na(loss_valid$GrossChargeOffAmount),]
# Training loss model
loss.mod <- lm(GrossChargeOffAmount~interestRate+unemploymentRate+hpiState+tedSpread+GrossApproval+TermInMonths+SBLR, data=loss_train)
summary(loss.mod)
# Testing loss model, computing MSE
loss.pred <- predict(loss.mod, newdata=loss_valid)
loss.pred <- loss.pred[!is.na(loss.pred)]
loss.mse <- mean((loss_valid$GrossChargeOffAmount-loss.pred)^2)
loss.mse
nrow(loss.pred)
length(loss.pred)
length(loss_valid$GrossChargeOffAmount)
?createTimeSlices
summary(loss.mod)
