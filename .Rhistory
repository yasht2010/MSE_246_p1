cov_matrix_indices <- function(a, b, c, d) {
# a, b, c, d refer to vectors, not objects
comatrix <- matrix(nrow=4, ncol=4)
# First set of correlations
comatrix[1,1] <- 52*cov(a,a)
comatrix[1,2] <- 52*cov(a,b)
comatrix[1,3] <- 52*cov(a,c)
comatrix[1,4] <- 52*cov(a,d)
# Second set of correlations
comatrix[2,1] <- comatrix[1,2]
comatrix[2,2] <- 52*cov(b,b)
comatrix[2,3] <- 52*cov(b,c)
comatrix[2,4] <- 52*cov(b,d)
# Third set of correlations
comatrix[3,1] <- comatrix[1,3]
comatrix[3,2] <- comatrix[2,3]
comatrix[3,3] <- 52*cov(c,c)
comatrix[3,4] <- 52*cov(c,d)
# Fourth set of correlations
comatrix[4,1] <- comatrix[1,4]
comatrix[4,2] <- comatrix[2,4]
comatrix[4,3] <- comatrix[3,4]
comatrix[4,4] <- 52*cov(d,d)
return(comatrix)
}
cov_matrix_f <- cov_matrix_indices(xoiweek$weekly.returns,xciweek$weekly.returns,xbdweek$weekly.returns,btkweek$weekly.returns)
View(cov_matrix_f)
xoi_var_yearly
xci_var_yearly
xci_var_week
gspc_var_week
gspc_var_yearly
xoi_var_yearly
xci_var_yearly
xbd_var_yearly
btk_var_yearly
xci_mk_cov <- 52*cov(xciweek$weekly.returns,gspcweek$weekly.returns)
xoi_mk_cov <- 52*cov(xoiweek$weekly.returns,gspcweek$weekly.returns)
xbd_mk_cov <- 52*cov(xbdweek$weekly.returns,gspcweek$weekly.returns)
btk_mk_cov <- 52*cov(btkweek$weekly.returns,gspcweek$weekly.returns)
xoi_mk_cov
xoi_mk_cov
xci_mk_cov
xbd_mk_cov
btk_mk_cov
library('quantmod')
?return
?return
?periodReturn
?getSymbols
test <- getSymbols('^XCI',auto.assign=FALSE)
View(test)
test[1,1]
view_t <- test[1,1]
view_t
symbols <- c('^XCI', '^XOI', '^XBD', '^BTK', '^XAU', '^XAL', '^XTC', '^XNG', 'FSRX', 'XLU')
ret_data <- c(rep(1,10))
for (i in 1:10) {
curr_data <- getSymbols(Symbols=symbols[i],auto.assign=FALSE,from='2016-07-27')
ret_val <- (curr_data[nrow(curr_data),4] - curr_data[1,1]) / curr_data[1,1]
ret_val <- ret_val - 1
ret_data[i] <- ret_val
}
symbols <- c('^XCI', '^XOI', '^XBD', '^BTK', '^XAU', '^XAL', '^XTC', '^XNG', 'FSRX', 'XLU')
ret_data <- c(rep(1,10))
for (i in 1:1) {
curr_data <- getSymbols(Symbols=symbols[i],auto.assign=FALSE,from='2016-07-27')
ret_val <- (curr_data[nrow(curr_data),4] - curr_data[1,1]) / curr_data[1,1]
print(ret_val)
ret_val <- ret_val - 1
ret_data[i] <- ret_val
}
symbols <- c('^XCI', '^XOI', '^XBD', '^BTK', '^XAU', '^XAL', '^XTC', '^XNG', 'FSRX', 'XLU')
ret_data <- c(rep(1,10))
for (i in 1:1) {
curr_data <- as.data.frame(getSymbols(Symbols=symbols[i],auto.assign=FALSE,from='2016-07-27'))
ret_val <- (curr_data[nrow(curr_data),4] - curr_data[1,1]) / curr_data[1,1]
print(ret_val)
ret_val <- ret_val - 1
ret_data[i] <- ret_val
}
symbols <- c('^XCI', '^XOI', '^XBD', '^BTK', '^XAU', '^XAL', '^XTC', '^XNG', 'FSRX', 'XLU')
ret_data <- c(rep(1,10))
for (i in 1:10) {
curr_data <- as.data.frame(getSymbols(Symbols=symbols[i],auto.assign=FALSE,from='2016-07-27'))
ret_val <- (curr_data[nrow(curr_data),4] - curr_data[1,1]) / curr_data[1,1]
ret_val <- ret_val - 1
ret_data[i] <- ret_val
}
traceback()
symbols <- c('^XCI', '^XOI', '^XBD', '^BTK', '^XAU', '^XAL', '^XTC', '^XNG', 'FSRFX', 'XLU')
ret_data <- c(rep(1,10))
for (i in 1:10) {
curr_data <- as.data.frame(getSymbols(Symbols=symbols[i],auto.assign=FALSE,from='2016-07-27'))
ret_val <- (curr_data[nrow(curr_data),4] - curr_data[1,1]) / curr_data[1,1]
ret_val <- ret_val - 1
ret_data[i] <- ret_val
}
ret_data
symbols <- c('FCX', 'ABX', 'HL', 'AUY', 'KGC', 'MS', 'SCHW', 'AMTD', 'GS', 'ETFC')
ret_data <- c(rep(1,10))
for (i in 1:10) {
curr_data <- as.data.frame(getSymbols(Symbols=symbols[i],auto.assign=FALSE,from='2016-07-27'))
ret_val <- (curr_data[nrow(curr_data),4] - curr_data[1,1]) / curr_data[1,1]
ret_val <- ret_val - 1
ret_data[i] <- ret_val
}
remove(view_t)
remove(test)
symbols <- c('FCX', 'ABX', 'HL', 'AUY', 'KGC', 'MS', 'SCHW', 'AMTD', 'GS', 'ETFC')
ret_data <- c(rep(1,10))
for (i in 1:10) {
curr_data <- as.data.frame(getSymbols(Symbols=symbols[i],auto.assign=FALSE,from='2016-07-27'))
ret_val <- (curr_data[nrow(curr_data),4] - curr_data[1,1]) / curr_data[1,1]
ret_val <- ret_val - 1
ret_data[i] <- ret_val
}
ret_data
min(ret_data)
max(ret_data
)
max(ret_data)
min(ret_data)
ret_data
symbols <- c('GOLD', 'RGLD', 'AEM', 'NEM', 'SLW', 'GS', 'MKTX', 'AMP', 'PJC', 'SF')
ret_data <- c(rep(1,10))
for (i in 1:10) {
curr_data <- as.data.frame(getSymbols(Symbols=symbols[i],auto.assign=FALSE,from='2016-07-27'))
ret_val <- (curr_data[nrow(curr_data),4] - curr_data[1,1]) / curr_data[1,1]
ret_val <- ret_val - 1
ret_data[i] <- ret_val
}
ret_data
max(ret_data)
min(ret_data)
install.packages('kernlab')
library('kernlab')
install.packages('~/Downloads/stringkernels_0.8.9.tar.gz', repos=NULL,type='source')
remove.packages('~/Downloads/stringkernels_0.8.9.tar.gz', repos=NULL,type='source')
remove.packages('~/Downloads/stringkernels_0.8.9.tar.gz')
remove.packages('stringkernels')
install.packages('stringkernels')
library('stringkernels')
?ksvm
?sk
?stringdot
?gapweightkernel
?stringdot
?data
data('reuters')
x<-reuters
View(x)
?kvsm
library('kernlab')
?kvsm
?ksvm
?cross
?`cross,ksvm-method`
View(y)
data('reuters')
y<-rlabels
View(y)
?plot
library('randomForest')
library('ISLR')
ncols(Carseats)
ncol(Carseats)
library('png')
install.packages('png')
library('png')
?readPNG
?rnorm
?pnorm
?hist
?rnorm
pnorm(0.95,0,1)
qnorm(0.95,0,1)
qnorm(0.975,0,1)
?xlim
?hist
?sample
?quantile
?set.seed
?.Random.seed
?which
as.POSIXct()
?as.POSIXct()
setwd('~/Desktop/Stanford Undergrad/MS&E 246/Project/Github Code/MSE_246_p1')
finalMatrix <- read.csv("big_data_Matrix.csv")
knitr::opts_chunk$set(echo = TRUE)
set.seed(1)
training_set=finalMatrix[1:520847,]
test_set=finalMatrix[520848+1:nrow(finalMatrix),]
filtered_set=filter(test_set,ApprovalFiscalYear==2008,TermInMonths>=60)
View(finalMatrix)
set.seed(1)
training_set=finalMatrix[1:520847,]
test_set=finalMatrix[520848+1:nrow(finalMatrix),]
filtered_set=filter(test_set,ApprovalFiscalYear==2008,termInMonths>=60)
# Starting the libraries
library(dplyr)
library(ROCR)
library(data.table)
set.seed(1)
training_set=finalMatrix[1:520847,]
test_set=finalMatrix[520848+1:nrow(finalMatrix),]
filtered_set=filter(test_set,ApprovalFiscalYear==2008,TermInMonths>=60)
filtered_set=filter(filtered_set,start==2008)
loans_sampled_test=sample(filtered_set$loanNum[1]:filtered_set$loanNum[nrow(filtered_set)],500,replace=FALSE)
loans_sampled_test=as.numeric(loans_sampled_test)
validation_set <- test_set[!(test_set$loanNum %in% loans_sampled_test),]
test500_set <- test_set[(test_set$loanNum %in% loans_sampled_test),]
set.seed(1)
df <- read.csv("SBA_loan_data_new.csv")
# Macroeconomic data sets
unemployment_data <- read.csv("emp-unemployment.csv")
interest_rates_data <- read.csv("FED_IR.csv")
Tornado_damage_economic <- read.csv("Tornado FL.csv")
Small_business_lending_data <- read.csv("Small_Business_lending_stats.csv")
GDPSectorData <- read.csv("GDP_Industry.csv")
TED <- read.csv("TEDRATE.csv")
SNP500 <- read.csv("SNP500.csv")
loss_train <- filter(training_set, isDefault == 1)
?unique
View(loss_train)
nrow(unique(loss_train$loanNum))
nrow(unique(loss_train, loanNum))
nrow(subset(loss_train, !duplicated(loanNum)))
?left_join
View(df)
?filter
?subset
?subset
?select
set.seed(1)
df <- read.csv("SBA_loan_data_new.csv")
# Macroeconomic data sets
unemployment_data <- read.csv("emp-unemployment.csv")
interest_rates_data <- read.csv("FED_IR.csv")
Tornado_damage_economic <- read.csv("Tornado FL.csv")
Small_business_lending_data <- read.csv("Small_Business_lending_stats.csv")
GDPSectorData <- read.csv("GDP_Industry.csv")
TED <- read.csv("TEDRATE.csv")
SNP500 <- read.csv("SNP500.csv")
set.seed(1)
SBLR <- c(rep(0,length(df$BorrState)))
for (i in 1:length(df$BorrState)) {
SBLR[i]=Small_business_lending_data[match(df$BorrState[i],Small_business_lending_data$State),5]
}
GDP <- c(rep(0,length(df$ApprovalFiscalYear)))
set.seed(1)
#Add small business loan ratio (total small business loans issued/total small businesses per state)
df=cbind(df,SBLR)
# Average HPI Index by State for 1990-2016
hpi_state <- read.csv("hpi_state.csv", header=TRUE, stringsAsFactors=F)
hpi_state$ProjectState = as.factor(hpi_state$ProjectState)
df <- left_join(df, hpi_state, by=c("ProjectState", "ApprovalFiscalYear"))
df$mn_hpi = as.numeric(df$mn_hpi)
# Filtering out Loans which are canceled or exempt
df <- filter(df, LoanStatus != "CANCLD")
df <- filter(df, LoanStatus != "EXEMPT")
df <- filter(df, DeliveryMethod != "504REFI")
set.seed(1)
df <- subset(df,select = -c(Program,BorrName,BorrStreet,
BorrZip,CDC_Street,CDC_City,CDC_Zip))
# adding isDefault
df$isDefault <- ifelse(df$LoanStatus=="CHGOFF",1,0)
for (i in 1:nrow(df)) {
if(df$LoanStatus[i]=="PIF"){df$isDefault[i]= 2}}
df$isDefault <- factor(df$isDefault)
df$isDefault <- as.numeric(df$isDefault)
# factor conversion
df$NotSameState <- factor(df$NotSameState)
df$ThirdPartyApproved <- factor(df$ThirdPartyApproved)
# adding dayselaped
df <- mutate(df,dayselapsed = as.numeric(difftime(strptime(ChargeOffDate, format = "%m/%d/%Y"),
strptime(ApprovalDate, format = "%m/%d/%Y"))))
df$dayselapsed[is.na(df$dayselapsed)]=round(df$TermInMonths*30.4)
df$dayselapsed[is.na(df$dayselapsed)] <- 7300
# adding FinalYear
df$FinalYear=df$ApprovalFiscalYear+round((df$dayselapsed)/365)
# Removing extra columns
df <- subset(df,select = -c(ThirdPartyLender_Name,ThirdPartyLender_City,ThirdPartyLender_State,
subpgmdesc,NaicsDescription,ProjectCounty,ProjectState))
# adding Naics2digits
df <- mutate(df,Naics2digits = substr(NaicsCode,1,2))
View(df)
?left_join
knitr::opts_chunk$set(echo = TRUE)
# Starting the libraries
library(dplyr)
library(ROCR)
library(data.table)
set.seed(1)
df <- read.csv("SBA_loan_data_new.csv")
# Macroeconomic data sets
unemployment_data <- read.csv("emp-unemployment.csv")
interest_rates_data <- read.csv("FED_IR.csv")
Tornado_damage_economic <- read.csv("Tornado FL.csv")
Small_business_lending_data <- read.csv("Small_Business_lending_stats.csv")
GDPSectorData <- read.csv("GDP_Industry.csv")
TED <- read.csv("TEDRATE.csv")
SNP500 <- read.csv("SNP500.csv")
set.seed(1)
SBLR <- c(rep(0,length(df$BorrState)))
for (i in 1:length(df$BorrState)) {
SBLR[i]=Small_business_lending_data[match(df$BorrState[i],Small_business_lending_data$State),5]
}
GDP <- c(rep(0,length(df$ApprovalFiscalYear)))
set.seed(1)
#Add small business loan ratio (total small business loans issued/total small businesses per state)
df=cbind(df,SBLR)
# Average HPI Index by State for 1990-2016
hpi_state <- read.csv("hpi_state.csv", header=TRUE, stringsAsFactors=F)
hpi_state$ProjectState = as.factor(hpi_state$ProjectState)
df <- left_join(df, hpi_state, by=c("ProjectState", "ApprovalFiscalYear"))
df$mn_hpi = as.numeric(df$mn_hpi)
# Filtering out Loans which are canceled or exempt
df <- filter(df, LoanStatus != "CANCLD")
df <- filter(df, LoanStatus != "EXEMPT")
df <- filter(df, DeliveryMethod != "504REFI")
set.seed(1)
df <- subset(df,select = -c(Program,BorrName,BorrStreet,
BorrZip,CDC_Street,CDC_City,CDC_Zip))
# adding isDefault
df$isDefault <- ifelse(df$LoanStatus=="CHGOFF",1,0)
for (i in 1:nrow(df)) {
if(df$LoanStatus[i]=="PIF"){df$isDefault[i]= 2}}
df$isDefault <- factor(df$isDefault)
df$isDefault <- as.numeric(df$isDefault)
# factor conversion
df$NotSameState <- factor(df$NotSameState)
df$ThirdPartyApproved <- factor(df$ThirdPartyApproved)
# adding dayselaped
df <- mutate(df,dayselapsed = as.numeric(difftime(strptime(ChargeOffDate, format = "%m/%d/%Y"),
strptime(ApprovalDate, format = "%m/%d/%Y"))))
df$dayselapsed[is.na(df$dayselapsed)]=round(df$TermInMonths*30.4)
df$dayselapsed[is.na(df$dayselapsed)] <- 7300
# adding FinalYear
df$FinalYear=df$ApprovalFiscalYear+round((df$dayselapsed)/365)
# Removing extra columns
df <- subset(df,select = -c(ThirdPartyLender_Name,ThirdPartyLender_City,ThirdPartyLender_State,
subpgmdesc,NaicsDescription,ProjectCounty,ProjectState))
# adding Naics2digits
df <- mutate(df,Naics2digits = substr(NaicsCode,1,2))
# Getting Interest Rates
set.seed(1)
interest_rates=matrix(0,nrow=length(df$ApprovalFiscalYear),ncol=length(1990:2014))
for (i in 1:length(1990:2014)) {
interest_rates[,i]=interest_rates_data[match(1989+i,interest_rates_data$Year),2]
}
interest_rates = interest_rates[1,]
# Initializing Matrix for Adding columns
set.seed(1)
matrix_test=matrix(0,nrow=0,ncol=23)
finalMatrix=matrix(0,nrow=0,ncol=23)
tempRow = matrix(0,nrow=1,ncol=23)
end_index=0
x=c("loanNum","start","stop","interestRate","gdpIndustry","unemploymentRate","hpiState","tedSpread","sandp500",
"BorrState","CDC_State","ThirdPartyDollars","GrossApproval","ApprovalDate","ApprovalFiscalYear","DeliveryMethod",
"TermInMonths","BusinessType","NotSameState","SBLR","Naics2digits","isDefault","endIndicator")
colnames(matrix_test)=x
df_const <- as.matrix(subset(df,select = c(BorrState,CDC_State,ThirdPartyDollars,GrossApproval,
ApprovalDate,ApprovalFiscalYear,DeliveryMethod,
TermInMonths,BusinessType,NotSameState,SBLR,Naics2digits)))
for (i in 1:nrow(df)) {
start=df$ApprovalFiscalYear[i]
stop=df$ApprovalFiscalYear[i]+round(df$dayselapsed[i]/365)
periods=length(start:stop)
n=0
unemployment_start_index=match(start,unemployment_data[1,])
unemployment_state_index=match(df$BorrState[i],unemployment_data[,3])
GDP_NAICS_index=match(df$Naics2digits[i],GDPSectorData[,2])
GDP_start_index=match(start,GDPSectorData[1,])
HPI_start_index=match(interaction(df$BorrState[i],start),
interaction(hpi_state$ProjectState, hpi_state$ApprovalFiscalYear))
if(stop<=2014){
for (j in 1:periods) {
tempRow = matrix(0,nrow=1,ncol=23)
tempRow[1,1]=i
tempRow[1,2]=start+n
tempRow[1,3]=start+n+1
tempRow[1,4] = interest_rates[start-1990+j]
tempRow[1,5]=GDPSectorData[GDP_NAICS_index,GDP_start_index+n]
tempRow[1,6]=unemployment_data[unemployment_state_index,unemployment_start_index+n]
tempRow[1,7]=hpi_state[HPI_start_index+n,3]
tempRow[1,8]=TED[start-1990+j,2]
tempRow[1,9]=SNP500[start-1990+j,1]
tempRow[1,as.numeric(10:21)] = df_const[i,]
if(df$isDefault[i]==2){
if((start+n)==stop){tempRow[1,22]=1
tempRow[1,23]=1}
}
if(start+n==stop) {tempRow[1,23]=1}
n=n+1
matrix_test <- rbind(matrix_test,tempRow)
}
}
else{
for (j in 1:(2014-start)) {
tempRow = matrix(0,nrow=1,ncol=23)
tempRow[1,1]=i
tempRow[1,2]=start+n
tempRow[1,3]=start+n+1
tempRow[1,4]=interest_rates[start-1990+j]
tempRow[1,5]=GDPSectorData[GDP_NAICS_index,GDP_start_index+n]
tempRow[1,6]=unemployment_data[unemployment_state_index,unemployment_start_index+n]
tempRow[1,7]=hpi_state[HPI_start_index+n,3]
tempRow[1,8]=TED[start-1990+j,2]
tempRow[1,9]=SNP500[start-1990+j,1]
tempRow[1,10:21] = df_const[i,]
if(df$isDefault[i]==2){
if((start+n)==stop){tempRow[1,22]=1
tempRow[1,23]=1}
}
if(unemployment_start_index+n==stop) {tempRow[1,23]=1}
if(j==2014-start){tempRow[1,23]=1}
n=n+1
matrix_test <- rbind(matrix_test,tempRow)
}
}
if(nrow(matrix_test)>=1000){
finalMatrix <- rbind(finalMatrix,matrix_test)
matrix_test=matrix(0,nrow=0,ncol=23)
}
}
finalMatrix <- rbind(finalMatrix,matrix_test)
finalMatrix=as.data.frame(finalMatrix)
# Convert ApprovalDate
finalMatrix <- mutate(finalMatrix, ApprovalDate = as.numeric(difftime(strptime(ApprovalDate, format ="%m/%d/%Y"),strptime("1/1/1990", format = "%m/%d/%Y"))))
finalMatrix$start <- as.numeric(as.character(finalMatrix$start))
finalMatrix$stop <- as.numeric(as.character(finalMatrix$stop))
finalMatrix$isDefault <- as.numeric(as.character(finalMatrix$isDefault))
finalMatrix$GrossApproval <- as.numeric(as.character(finalMatrix$GrossApproval))
finalMatrix$unemploymentRate <- as.numeric(as.character(finalMatrix$unemploymentRate))
finalMatrix$interestRate <- as.numeric(as.character(finalMatrix$interestRate))
finalMatrix$hpiState <- as.numeric(as.character(finalMatrix$hpiState))
finalMatrix$TermInMonths <- as.numeric(as.character(finalMatrix$TermInMonths))
finalMatrix$SBLR <- as.numeric(as.character(finalMatrix$SBLR))
finalMatrix$tedSpread <-as.numeric(as.character(finalMatrix$tedSpread))
finalMatrix$sandp500 <- as.numeric(as.character(finalMatrix$sandp500))
finalMatrix$loanNum <- as.numeric(as.character(finalMatrix$loanNum))
# Export file
#write.csv(finalMatrix, file="big_data_Matrix.csv", col.names=FALSE)
set.seed(1)
training_set=finalMatrix[1:520847,]
test_set=finalMatrix[520848+1:nrow(finalMatrix),]
filtered_set=filter(test_set,ApprovalFiscalYear==2008,TermInMonths>=60)
filtered_set=filter(filtered_set,start==2008)
loans_sampled_test=sample(filtered_set$loanNum[1]:filtered_set$loanNum[nrow(filtered_set)],500,replace=FALSE)
loans_sampled_test=as.numeric(loans_sampled_test)
validation_set <- test_set[!(test_set$loanNum %in% loans_sampled_test),]
test500_set <- test_set[(test_set$loanNum %in% loans_sampled_test),]
library(survival)
library(peperr)
## COX REGRESSION
#cox_reg <- coxph(Surv(start,stop,isDefault)~sandp500,data=training_set)
cox_reg=coxph(Surv(start,stop,isDefault)~GrossApproval+unemploymentRate+hpiState+
SBLR+TermInMonths,
data=training_set)
singulartest <- lm(sandp500~GrossApproval+unemploymentRate+hpiState+BusinessType+TermInMonths+SBLR,data=training_set)
time_eval=c(2008,2009,2010)
time_eval2=2008
test_set_time_eval=filter(test_set,start==time_eval)
test_set_time_eval2=filter(test_set,start==time_eval2)
#test_set_final_year=filter(test_set)
s.scr <- survival::Surv(rep(2, nrow(test_set_time_eval)),rep(1, nrow(test_set_time_eval)) )
s.scr2 <- survival::Surv(rep(2, nrow(test_set_time_eval2)),rep(1, nrow(test_set_time_eval2)) )
pred_cox_model= predictProb.coxph(cox_reg,s.scr,test_set_time_eval,time_eval)
pred_cox_model2=predictProb.coxph(cox_reg,s.scr2,test_set_time_eval2,time_eval2)
matrix_verify=rep(0,nrow(pred_cox_model))
pred_cox_model=na.omit(pred_cox_model)
for (i in 1:nrow(pred_cox_model)) {
if ((pred_cox_model[i,2]-pred_cox_model[i,1])>0) {matrix_verify[i]=1}
if ((pred_cox_model[i,3]-pred_cox_model[i,2])>0) {matrix_verify[i]=1}
if ((pred_cox_model[i,4]-pred_cox_model[i,3])>0) {matrix_verify[i]=1}
if ((pred_cox_model[i,5]-pred_cox_model[i,4])>0) {matrix_verify[i]=1}
}
View(pred_cox_model)
library(survival)
library(peperr)
## COX REGRESSION
#cox_reg <- coxph(Surv(start,stop,isDefault)~sandp500,data=training_set)
cox_reg=coxph(Surv(start,stop,isDefault)~GrossApproval+unemploymentRate+hpiState+
SBLR+TermInMonths,
data=training_set)
singulartest <- lm(sandp500~GrossApproval+unemploymentRate+hpiState+BusinessType+TermInMonths+SBLR,data=training_set)
time_eval=c(2008,2009,2010, 2011, 2012)
time_eval2=2008
test_set_time_eval=filter(test_set,start==time_eval)
test_set_time_eval2=filter(test_set,start==time_eval2)
#test_set_final_year=filter(test_set)
s.scr <- survival::Surv(rep(2, nrow(test_set_time_eval)),rep(1, nrow(test_set_time_eval)) )
s.scr2 <- survival::Surv(rep(2, nrow(test_set_time_eval2)),rep(1, nrow(test_set_time_eval2)) )
pred_cox_model= predictProb.coxph(cox_reg,s.scr,test_set_time_eval,time_eval)
pred_cox_model2=predictProb.coxph(cox_reg,s.scr2,test_set_time_eval2,time_eval2)
matrix_verify=rep(0,nrow(pred_cox_model))
pred_cox_model=na.omit(pred_cox_model)
for (i in 1:nrow(pred_cox_model)) {
if ((pred_cox_model[i,2]-pred_cox_model[i,1])>0) {matrix_verify[i]=1}
if ((pred_cox_model[i,3]-pred_cox_model[i,2])>0) {matrix_verify[i]=1}
if ((pred_cox_model[i,4]-pred_cox_model[i,3])>0) {matrix_verify[i]=1}
if ((pred_cox_model[i,5]-pred_cox_model[i,4])>0) {matrix_verify[i]=1}
}
pred_cox_model
pred = predict(cox_reg,test_set,type="expected")
prob_default=1-exp(pred)
plot(survfit(cox_reg),ylim=c(0.6,1),xlim=c(1990,2014))
summary(cox_reg)
## LOGISTIC REGRESSION
log_reg=glm(isDefault ~ GrossApproval+hpiState+TermInMonths+SBLR+sandp500+unemploymentRate+BusinessType,family=binomial,data=training_set)
pred_log_reg=predict(log_reg,test_set,type="response")
