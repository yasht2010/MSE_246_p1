---
title: "Loss Given Default + VaR"
author: "Daniel Bereket"
date: "3/22/2017"
output: pdf_document
---

# Loss Given Default

```{r}
library(tree)
library(randomForest)
library(splines)
library(dplyr)

## DATA DOWNLOAD & CLEANING

# Getting original data for Charge-off Amounts
df <- read.csv('SBA_cleaned_data.csv')
chg_vals <- select(df, GrossChargeOffAmount)
chg_vals$loanNum <- c(1:nrow(df))



## Set up loss training set
loss_train <- read.csv('training_set.csv')
loss_train <- loss_train[loss_train$isDefault==1,]

# Cleaning NA values for training set
loss_train <- loss_train[!is.na(loss_train$interestRate),]
loss_train <- loss_train[!is.na(loss_train$unemploymentRate),]
loss_train <- loss_train[!is.na(loss_train$hpiState),]
loss_train <- loss_train[!is.na(loss_train$tedSpread),]
loss_train <- loss_train[!is.na(loss_train$sandp500),]
loss_train <- loss_train[!is.na(loss_train$TermInMonths),]

# Merging Charge-off Amounts for training set
loss_train <- left_join(loss_train, chg_vals, by="loanNum") # adding charge off values

# Creating loss ratios
loss_train$LossRatio <- loss_train$GrossChargeOffAmount / loss_train$GrossApproval

# Removing loss ratios above 1
loss_train <- loss_train[loss_train$LossRatio<=1,]

# Log variable transformations
loss_train$loggross <- log(loss_train$GrossApproval)
loss_train$loghpi <- log(loss_train$hpiState)



# Set up loss validation set
loss_valid <- read.csv('validation_set.csv')
loss_valid <- loss_valid[loss_valid$isDefault==1,]

# Merging Charge-off Amounts for validation set
loss_valid <- left_join(loss_valid, chg_vals, by="loanNum") # adding charge off values

# Cleaning NA values for validation set
loss_valid <- loss_valid[!is.na(loss_valid$interestRate),]
loss_valid <- loss_valid[!is.na(loss_valid$unemploymentRate),]
loss_valid <- loss_valid[!is.na(loss_valid$hpiState),]
loss_valid <- loss_valid[!is.na(loss_valid$tedSpread),]
loss_valid <- loss_valid[!is.na(loss_valid$sandp500),]
loss_valid <- loss_valid[!is.na(loss_valid$TermInMonths),]


# Creating loss ratios
loss_valid$LossRatio <- loss_valid$GrossChargeOffAmount / loss_valid$GrossApproval

# Removing loss ratios above 1
loss_valid <- loss_valid[loss_valid$LossRatio<=1,]

# Log variable transformations
loss_valid$loggross <- log(loss_valid$GrossApproval)
loss_valid$loghpi <- log(loss_valid$hpiState)



## LOSS GIVEN DEFAULT MODELS

# Linear regression (threshold)
loss.lm <- lm(LossRatio~log(GrossApproval)+interestRate+unemploymentRate+log(hpiState)+tedSpread+sandp500+TermInMonths, data=loss_train,na.action=na.exclude)
summary(loss.lm)

lm.losspred <- predict(loss.lm, newdata=loss_valid)
lm.mse <- mean((lm.losspred-loss_valid$LossRatio)^2)
lm.mse

# Bagging trees
bag.tree <- randomForest(LossRatio~loggross+interestRate+unemploymentRate+loghpi+tedSpread+sandp500+TermInMonths, data=loss_train, mtry=7, ntree=90)
summary(bag.tree)

bag.losspred <- predict(bag.tree, newdata=loss_valid, type="response")
bag.mse <- mean((bag.losspred-loss_valid$LossRatio)^2)
bag.mse

# Random forests
rf.tree <- randomForest(GrossChargeOffAmount~loggross+interestRate+unemploymentRate+loghpi+tedSpread+sandp500+TermInMonths, data=loss_train, mtry=2, ntree=90)
summary(bag.tree)

rf.losspred <- predict(rf.tree, newdata=loss_valid, type="response")
rf.mse <- mean((rf.losspred-loss_valid$LossRatio)^2)
rf.mse

# Regression splines
loss.spl <- lm(LossRatio~bs(interestRate,df=3)+bs(unemploymentRate,df=3)+bs(log(hpiState),df=3)+bs(tedSpread,df=3)+bs(sandp500,df=3)+bs(TermInMonths,df=3),data=loss_train)

spl.losspred <- predict(loss.spl,newdata=loss_valid)

spl.mse <- mean((spl.losspred-loss_valid$LossRatio)^2)
spl.mse

```



# Reading/Cleaning Test Datasets

```{r}

## FULL DATASET
test500_set <- read.csv('test500_full.csv')

# Reading probabilities
def.probs <- read.csv("prob.csv") 
names(def.probs)[2] <- "loanNum"
def.probs <- select(def.probs, loanNum, Prob1yr, Prob5yr)

# Join tables
names(test500_set)[2] <- "loanNum"
names(test500_set)[1] <- "loanNum1"
test500_set <- left_join(test500_set, def.probs, by="loanNum")


# Creating log hpi state column for test set
test500_set$loghpi <- log(test500_set$hpiState)
test500_set$loggross <- log(test500_set$GrossApproval)

## ONE YEAR TEST DATASET

test500.1 <- test500_set[test500_set$ApprovalFiscalYear==test500_set$start,]
test500.1 <- left_join(test500.1, chg_vals, by="loanNum")

# Filtering probabilites to those for one year
def.probs.1 <- def.probs[!is.na(test500.1$interestRate),]
def.probs.1 <- def.probs.1[!is.na(test500.1$unemploymentRate),]
def.probs.1 <- def.probs.1[!is.na(test500.1$hpiState),]

# Cleaning NA values for 1-year test set
test500.1 <- test500.1[!is.na(test500.1$interestRate),]
test500.1 <- test500.1[!is.na(test500.1$unemploymentRate),]
test500.1 <- test500.1[!is.na(test500.1$hpiState),]
test500.1 <- test500.1[!is.na(test500.1$tedSpread),]
test500.1 <- test500.1[!is.na(test500.1$sandp500),]
test500.1 <- test500.1[!is.na(test500.1$TermInMonths),]

# Loss predictions
test.loss.1 <- predict(bag.tree, newdata=test500.1, type="response")

## FIVE YEAR TEST DATASET

# Getting default events
test500.5 <- test500_set[test500_set$start==test500_set$ApprovalFiscalYear,]

test.def <- test500_set[test500_set$isDefault==1,]
test.def <- test.def[test.def$stop<=test.def$ApprovalFiscalYear+5,]

# Cleaning NA values for 5-year test set
test500.5 <- test500.5[!is.na(test500.5$interestRate),]
test500.5 <- test500.5[!is.na(test500.5$unemploymentRate),]
test500.5 <- test500.5[!is.na(test500.5$hpiState),]
test500.5 <- test500.5[!is.na(test500.5$tedSpread),]
test500.5 <- test500.5[!is.na(test500.5$sandp500),]
test500.5 <- test500.5[!is.na(test500.5$TermInMonths),]

# Setting correct default events for 5-year horizon
for (i in 1:nrow(test.def)) {
  val <- test.def$loanNum[i]
  test500.5[test500.5$loanNum==val,24] <- 1
  test500.5
}

test500.5 <- left_join(test500.5, chg_vals, by="loanNum")

# Loss predictions
test.loss.5 <- predict(bag.tree, newdata=test500.5, type="response")
```



# Parametric VaR

```{r}
library(ggplot2)

## ONE YEAR LOSSES

firstloss.1 <- rep(0,10000)
loss.var95.1 <- rep(0,10000)
loss.avar95.1 <- rep(0,10000)
loss.var99.1 <- rep(0,10000)
loss.avar99.1 <- rep(0,10000)

set.seed(1)

# Simulation
for (i in 1:10000) {
  r.prob <- runif(1,0,1)
  
  def.events <- rep(0, nrow(def.probs.1))
  def.events <- ifelse(def.probs.1$Prob1yr>=r.prob,1,0)
  
  
  def.loss <- test.loss.1 * test500.1$GrossApproval * def.events
  
  def.total.loss <- sum(def.loss)
  firstloss.1[i] <- def.total.loss
  
}

# Create loss matrix
nvals <- firstloss.1[firstloss.1>0]
loss.matrix.1 <- matrix(nrow=10000, ncol=length(nvals))

# Plot losses
ls.1 <- ggplot() + geom_density(mapping=aes(x=nvals))
ls.1


# Bootstrapping simulated values
for (i in 1:10000) {
  boot.loss.inds <- sample(1:length(nvals), length(nvals), replace=TRUE)
  boot.loss <- nvals[boot.loss.inds]

  
  loss.matrix.1[i,] <- boot.loss
  
  # Calculating VaR
  loss.var95.1[i] <- quantile(boot.loss, probs=seq(0.95), na.rm=TRUE)
  loss.var99.1[i] <- quantile(boot.loss, probs=seq(0.99), na.rm=TRUE)
 
}


# Plot VaR Values
pl.95.1 <- ggplot() + geom_density(mapping=aes(x=loss.var95.1))
pl.95.1
pl.99.1 <- ggplot() + geom_density(mapping=aes(x=loss.var99.1))
pl.99.1


# Tranches
lossvector.1 <- as.vector(loss.matrix.1)

maxloss <- sum(test500.1$GrossApproval)
thresh5.1 <- 0.05*maxloss
thresh15.1 <- 0.15*maxloss

junior.tranche.1 <- rep(0, length(lossvector.1))
senior.tranche.1 <- rep(0, length(lossvector.1))

for (i in 1:length(lossvector.1)) {
  junior.tranche.1[i] <- ifelse(lossvector.1[i] > thresh5.1, min(100, 100*((lossvector.1[i]-thresh5.1)/(thresh15.1-thresh5.1))), 0)
  
  senior.tranche.1[i] <- ifelse(lossvector.1[i] > thresh15.1, min(100, 100*((lossvector.1[i]-thresh15.1)/(maxloss-thresh15.1))), 0)
}

junior.plot.1 <- ggplot() + geom_density(mapping=aes(x=junior.tranche.1))
junior.plot.1
senior.plot.1 <- ggplot() + geom_density(mapping=aes(x=senior.tranche.1))
senior.plot.1


## FIVE YEAR LOSSES

firstloss.5 <- rep(0,10000)
loss.var95.5 <- rep(0,10000)
loss.avar95.5 <- rep(0,10000)
loss.var99.5 <- rep(0,10000)
loss.avar99.5 <- rep(0,10000)

# Simulate defaults
for (i in 1:10000) {
  r.prob <- runif(1,0,1)
  
  def.events <- ifelse(def.probs$Prob5yr>=r.prob,1,0)
  def.loss <- test.loss.5 * test500.5$GrossApproval * def.events
  
  def.total.loss <- sum(def.loss)
  firstloss.5[i] <- def.total.loss
}

# Create loss matrix
nvals <- firstloss.5[firstloss.5>0]
loss.matrix.5 <- matrix(nrow=10000, ncol=length(nvals))

# Plot losses
ls.5 <- ggplot() + geom_density(mapping=aes(x=nvals))
ls.5

# Bootstrapping
for (i in 1:10000) {
  boot.loss.inds <- sample(1:length(nvals), length(nvals), replace=TRUE)
  boot.loss <- nvals[boot.loss.inds]
  
  loss.matrix.5[i,] <- boot.loss
  
  # Calculating VaR
  loss.var95.5[i] <- quantile(boot.loss, probs=0.95,na.rm=TRUE)
  loss.var99.5[i] <- quantile(boot.loss, probs=0.99,na.rm=TRUE)
}

# Plot VaR curves
pl.95.5 <- ggplot() + geom_density(mapping=aes(x=loss.var95.5))
pl.95.5
pl.99.5 <- ggplot() + geom_density(mapping=aes(x=loss.var99.5))
pl.99.5

# Tranches
maxloss <- sum(test500.5$GrossApproval)

lossvector.5 <- as.vector(loss.matrix.5)

thresh5.5 <- 0.05*maxloss
thresh15.5 <- 0.15*maxloss

junior.tranche.5 <- rep(0, length(lossvector.5))
senior.tranche.5 <- rep(0, length(lossvector.5))

for (i in 1:length(lossvector.5)) {
  junior.tranche.5[i] <- ifelse(lossvector.5[i] > thresh5.5, min(100, 100*((lossvector.5[i]-thresh5.5)/(thresh15.5-thresh5.5))), 0)
  
  senior.tranche.5[i] <- ifelse(lossvector.5[i] > thresh15.5, min(100, 100*((lossvector.5[i]-thresh15.5)/(maxloss-thresh15.5))), 0)
}

junior.plot.5 <- ggplot() + geom_density(mapping=aes(x=junior.tranche.5))
junior.plot.5

senior.plot.5 <- ggplot() + geom_density(mapping=aes(x=senior.tranche.5))
senior.plot.5

```


# Non-parametric VaR

```{r}
## ONE YEAR LOSSES

np.firstloss.1 <- rep(0,10000)
np.loss.var95.1 <- rep(0,10000)
np.loss.avar95.1 <- rep(0,10000)
np.loss.var99.1 <- rep(0,10000)
np.loss.avar99.1 <- rep(0,10000)

set.seed(1)

# Simulation
for (i in 1:10000) {
  r.prob <- runif(1,0,1)
  
  def.events <- rep(0, nrow(def.probs.1))
  def.events <- ifelse(def.probs.1$Prob1yr<=r.prob,1,0)
  
  
  def.loss <- test500.1$GrossChargeOffAmount * def.events
  
  def.total.loss <- sum(def.loss)
  np.firstloss.1[i] <- def.total.loss
  
}

# Create loss matrix
nvals <- np.firstloss.1[np.firstloss.1>0]
np.loss.matrix.1 <- matrix(nrow=10000, ncol=length(nvals))

# Plot losses
np.ls.1 <- ggplot() + geom_density(mapping=aes(x=nvals))
np.ls.1


# Bootstrapping simulated values
for (i in 1:10000) {
  boot.loss.inds <- sample(1:length(nvals), length(nvals), replace=TRUE)
  boot.loss <- nvals[boot.loss.inds]

  
  np.loss.matrix.1[i,] <- boot.loss
  
  # Calculating VaR
  np.loss.var95.1[i] <- quantile(boot.loss, probs=seq(0.95), na.rm=TRUE)
  np.loss.var99.1[i] <- quantile(boot.loss, probs=seq(0.99), na.rm=TRUE)
 
}


# Plot VaR Values
np.pl.95.1 <- ggplot() + geom_density(mapping=aes(x=loss.var95.1))
np.pl.95.1
np.pl.99.1 <- ggplot() + geom_density(mapping=aes(x=loss.var99.1))
np.pl.99.1


# Tranches
np.lossvector.1 <- as.vector(loss.matrix.1)

maxloss <- sum(test500.1$GrossApproval)
np.thresh5.1 <- 0.05*maxloss
np.thresh15.1 <- 0.15*maxloss

np.junior.tranche.1 <- rep(0, length(np.lossvector.1))
np.senior.tranche.1 <- rep(0, length(np.lossvector.1))

for (i in 1:length(np.lossvector.1)) {
  np.junior.tranche.1[i] <- ifelse(np.lossvector.1[i] > np.thresh5.1, min(100, 100*((np.lossvector.1-np.thresh5.1)/(np.thresh15.1-np.thresh5.1))), 0)
  
  np.senior.tranche.1[i] <- ifelse(np.lossvector.1[i] > np.thresh15.1, min(100, 100*((np.lossvector.1-np.thresh15.1)/(maxloss-np.thresh15.1))), 0)
}


np.junior.plot.1 <- ggplot() + geom_density(mapping=aes(x=np.junior.tranche.1))
np.junior.plot.1

np.senior.plot.1 <- ggplot() + geom_density(mapping=aes(x=np.senior.tranche.1))
np.senior.plot.1


## FIVE YEAR LOSSES

np.firstloss.5 <- rep(0,10000)
np.loss.var95.5 <- rep(0,1000)
np.loss.avar95.5 <- rep(0,1000)
np.loss.var99.5 <- rep(0,1000)
np.loss.avar99.5 <- rep(0,1000)

# Simulate defaults
for (i in 1:10000) {
  r.prob <- runif(1,0,1)
  
  def.events <- ifelse(def.probs$Prob5yr<=r.prob,1,0)
  def.loss <- test.loss.5 * test500_set$GrossApproval * def.events
  
  def.total.loss <- sum(def.loss)
  np.firstloss.5[i] <- def.total.loss
}

# Create loss matrix
nvals <- np.firstloss.5[np.firstloss.5>0]
np.loss.matrix.5 <- matrix(nrow=10000, ncol=length(nvals))

# Plot losses
np.ls.5 <- ggplot() + geom_density(mapping=aes(x=nvals))
np.ls.5

# Bootstrapping
for (i in 1:10000) {
  boot.loss.inds <- sample(1:length(nvals), length(nvals), replace=TRUE)
  boot.loss <- nvals[boot.loss.inds]
  
  np.loss.matrix.1[i,] <- boot.loss
  
  # Calculating VaR
  np.loss.var95.5[i] <- quantile(boot.loss, probs=0.95,na.rm=TRUE)
  np.loss.var99.5[i] <- quantile(boot.loss, probs=0.99,na.rm=TRUE)
}

# Plot VaR curves
np.pl.95.5 <- ggplot() + geom_density(mapping=aes(x=loss.var95.5))
np.pl.95.5
np.pl.99.5 <- ggplot() + geom_density(mapping=aes(x=loss.var99.5))
np.pl.99.5

# Tranches
np.lossvector.5 <- as.vector(loss.matrix.5)

np.thresh5.5 <- 0.05*maxloss
np.thresh15.5 <- 0.15*maxloss

np.junior.tranche.5 <- rep(0, length(np.lossvector.5))
np.senior.tranche.5 <- rep(0, length(np.lossvector.5))

for(i in 1:length(np.lossvector.5)) {
  np.junior.tranche.5[i] <- ifelse(np.lossvector.5[i] > np.tresh5.5, min(100, 100*((np.lossvector.5[i]-np.thresh5.5)/(np.thresh15.5-np.thresh5.5))), 0)
  
  np.senior.tranche.5[i] <- ifelse(np.lossvector.5[i] > np.thresh15.5, min(100, 100*((np.lossvector.5[i]-np.thresh15.5)/(maxloss-np.thresh15.5))), 0)
}

np.junior.plot.5 <- ggplot() + geom_density(mapping=aes(x=np.junior.tranche.5))
np.junior.plot.5

np.senior.plot.5 <- ggplot() + geom_density(mapping=aes(x=np.senior.tranche.5))
np.senior.plot.5



```